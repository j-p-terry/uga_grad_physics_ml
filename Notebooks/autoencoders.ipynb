{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e94a75-f431-431e-bc1f-3ca8e7d9a382",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm \n",
    "from matplotlib import rc as mplrc\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import PIL\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint, progress\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.loggers import WandbLogger, TensorBoardLogger\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torch.utils.data import DataLoader, Dataset, RandomSampler, random_split\n",
    "\n",
    "import torchmetrics\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51feab6e-a744-475a-be91-b7442966093b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set seed for reproducibility\n",
    "np.random.seed(123)\n",
    "random.seed(123)\n",
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d476e7c3-373c-4ed4-8b57-a6324e1eccc1",
   "metadata": {},
   "source": [
    "# About\n",
    "\n",
    "### Latent Space\n",
    "A latent space is a mathematical representation of data that captures its important features or patterns. It's a way to simplify complex data and extract useful information. The information is, in a sense, compressed into a lower dimensional space that still contains enough information to perform whatever task you want. A common task is attempting to output the input. This can be useful for anomaly detection or denoising (with slight modifications to input data). I can, for example, take a 28x28 image, compress it through a series of convolutions into a 16 component latent space vector, then upsample it as I convolve to output a 28x28 image. In this way, I learn how to map input data into a useful representation (encoding) and map this representation into a desired ouput (decoding). This is also the basis for many language models, such as sequence-to-sequence models (translation - universal grammar?)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5abfca-c8b8-455b-989c-0ae9cb20c9cf",
   "metadata": {},
   "source": [
    "<img src=\"imgs/autoencoder_visualization.svg\" style=\"height:600px\" class=\"center\" alt=\"ae\"/><br>\n",
    "\n",
    "A simple representation of an autoencoder. Think of it as a bottle kneck into a smaller latent space and an upsample out of this space back into the output space (whatever that may be). In this case, it's attempting to recreate the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f202e41-8649-431d-af20-354e8a5c5a3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f3d5e0f5-4576-4244-9cdc-03350275e8ec",
   "metadata": {},
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0e8ada-8b2b-4f4b-8946-39e621286bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Download fashion MNIST\n",
    "train_dataset = datasets.FashionMNIST(\n",
    "    root='./data', train=True, download=True,)\n",
    "test_dataset = datasets.FashionMNIST(\n",
    "    root='./data', train=False, download=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70fcd63-0333-4421-b09f-fda5c6b39c8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "78b8b348-05aa-45de-8930-53c12e1c9b37",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e060aa7-ba26-4ce2-bd88-03a66d1df4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_dataset.data.detach().numpy()\n",
    "X_test = test_dataset.data.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5564ed80-2554-4688-98a3-e5dcbf028dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize\n",
    "X_train = (X_train - np.min(X_train)) / np.max(X_train - np.min(X_train))\n",
    "X_test = (X_test - np.min(X_test)) / np.max(X_test - np.min(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54723644-f271-4abc-be3c-ff28a3edce1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PyTorch uses Dataset objects to load the data during training and testing\n",
    "class MNISTDataset(Dataset):\n",
    "\n",
    "    \"\"\"Data set\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        X: np.ndarray,\n",
    "        noisy_X: np.ndarray,\n",
    "        accelerator_name: str = \"mps\",\n",
    "        \n",
    "    ):\n",
    "        '''Assign data'''\n",
    "        self.X = X.astype(np.float32)\n",
    "        self.noisy_X = noisy_X.astype(np.float32)\n",
    "\n",
    "        if accelerator_name == \"mps\":\n",
    "            self.device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "        elif accelerator_name == \"cuda:0\":\n",
    "            self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        else:\n",
    "            self.device = torch.device(\"cpu\")\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        '''function to get the length of the dataset'''\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        '''return an x, y pair'''\n",
    "        x_, noisy_x_ = self.X[idx].astype(np.float32), self.noisy_X[idx].astype(np.float32)\n",
    "\n",
    "        return torch.from_numpy(x_).float().to(self.device), torch.from_numpy(noisy_x_).float().to(self.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30beec86-be98-40cb-8135-050e48d5ddb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into validation and training data\n",
    "val_split = 0.2\n",
    "X_train, X_val = train_test_split(X_train,\n",
    "                                  test_size=val_split,\n",
    "                                  random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dba08c7-4955-42bf-9f15-5399c90d5c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add channel axes (N, H, W) -> (N, C, H, W) because C = 1 in this case\n",
    "X_train = X_train[:, np.newaxis, :, :].astype(np.float32)\n",
    "X_test = X_test[:, np.newaxis, :, :].astype(np.float32)\n",
    "X_val = X_val[:, np.newaxis, :, :].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0d61d9-d254-4ddc-9e9d-c56de802e47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_X_train = X_train.copy().astype(np.float32)\n",
    "noisy_X_test = X_test.copy().astype(np.float32)\n",
    "noisy_X_val = X_val.copy().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48aca1b-9a7c-40cc-adad-1e134bdc8fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_level = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd1d857-2178-40fe-9686-30685fdd2ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_X_train += noise_level * np.random.standard_normal(X_train.shape)\n",
    "noisy_X_train -= np.min(noisy_X_train)\n",
    "noisy_X_train /= np.max(noisy_X_train)\n",
    "\n",
    "noisy_X_val += noise_level * np.random.standard_normal(X_val.shape)\n",
    "noisy_X_val -= np.min(noisy_X_val)\n",
    "noisy_X_val /= np.max(noisy_X_val)\n",
    "\n",
    "noisy_X_test += noise_level * np.random.standard_normal(X_test.shape)\n",
    "noisy_X_test -= np.min(noisy_X_test)\n",
    "noisy_X_test /= np.max(noisy_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519d273b-4cfe-4d4f-81a1-6e8354de48c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get H = W\n",
    "input_xy = X_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6437c506-d28f-4989-bfcd-b46405c4b37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c5a18c-2f62-4f81-91db-31d315b653aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Now we actually make the dataset and dataloader in PyTorch fashion\n",
    "train_data = MNISTDataset(X_train, noisy_X_train)\n",
    "val_data = MNISTDataset(X_val, noisy_X_val)\n",
    "test_data = MNISTDataset(X_test, noisy_X_test)\n",
    "\n",
    "# make the loader\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd4cfee-7105-413b-998c-7cad00fac219",
   "metadata": {},
   "source": [
    "# Define Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9df722-b663-4969-8131-6e17bddce346",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b570c9fd-003c-47b4-844a-1535586077ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, \n",
    "                 kernel_size: int = 3, \n",
    "                 dropout: float = 0.25,\n",
    "                 cnn_layer_dims: list = [126, 64, 32],\n",
    "                 padding: int = 1, \n",
    "                 stride: int = 2,\n",
    "                 n_channels: int = 1,\n",
    "                 input_xy: int = 28, \n",
    "                 lr: float = 1e-4, \n",
    "                 weight_decay: float = 0., \n",
    "                 eps: float = 5e-7, \n",
    "                 activation: torch.nn.modules.activation = nn.GELU(),\n",
    "                 use_wandb: bool=False,\n",
    "                 scheduler_name: str = \"none\",\n",
    "                 step_size: int = 5,\n",
    "                 gamma: float = 0.5,\n",
    "                 ) -> None:\n",
    "        super().__init__()\n",
    "        ### Always need to call above function first in order\n",
    "        ### to properly initialize a model\n",
    "        '''Basic CNN to classify fashion MNIST\n",
    "        We aren't going to both with some of the fancier stuff from the MLP, but it's easy enough to apply here too\n",
    "        '''\n",
    "        \n",
    "        # model parameters\n",
    "        self.cnn_dims = cnn_layer_dims\n",
    "        self.activation = activation\n",
    "        self.lr = lr\n",
    "        self.eps = eps\n",
    "        self.weight_decay = weight_decay\n",
    "        self.dropout = dropout\n",
    "        self.n_cnn_layers = len(cnn_layer_dims)\n",
    "        self.scheduler_name = scheduler_name\n",
    "        # if using a scheduler\n",
    "        self.step_size = step_size\n",
    "        self.gamma = gamma\n",
    "        \n",
    "        # log using WandB or TensorBoard\n",
    "        self.use_wandb = use_wandb\n",
    "        \n",
    "        # what the input data looks like (allows construction of graph for logging)\n",
    "        # (batch_size, channels, height, width)\n",
    "        self.example_input_array = torch.zeros(\n",
    "            (1, n_channels, input_xy, input_xy,),\n",
    "            dtype=torch.float32\n",
    "        )\n",
    "        \n",
    "        #### Construct the layers #####\n",
    "        ## get input layer\n",
    "        ## shape = (C, H, W) -> (cnn_layer_dim, H, W)\n",
    "        self.input_cnn = nn.Conv2d(n_channels, cnn_layer_dims[0], \n",
    "                                   kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "        \n",
    "        ## make CNN hidden layers\n",
    "        self.encoding_layers = []\n",
    "        for i in range(1, self.n_cnn_layers):\n",
    "            self.encoding_layers.append(nn.Conv2d(cnn_layer_dims[i-1], cnn_layer_dims[i], \n",
    "                                       kernel_size=kernel_size, stride=stride, padding=padding))\n",
    "\n",
    "        self.encoding_layers = nn.ModuleList(self.encoding_layers)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self) -> None:\n",
    "        ### does some fancy layer weight initialization\n",
    "        for layer in self.encoding_layers:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                nn.init.xavier_uniform_(layer.weight)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        '''Determines how data is passed through the network, \n",
    "           i.e creates the connectivity of the network'''\n",
    "        \n",
    "        ## send through input layer and activate\n",
    "        x = self.activation(self.input_cnn(x))\n",
    "        ## do max pooling (2x2)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "            \n",
    "        # pass through CNN\n",
    "        for layer in self.encoding_layers:\n",
    "            # pass through layer and activate\n",
    "            x = layer(x)\n",
    "            x = self.activation(x)\n",
    "            # pool\n",
    "            x = F.max_pool2d(x, 2)\n",
    "        \n",
    "        return x\n",
    "\n",
    "    def configure_optimizers(self) -> (list, list):\n",
    "        \"\"\"Set up the optimizer and potential learning rate scheduler\"\"\"\n",
    "        self.optimizer = torch.optim.AdamW(\n",
    "            self.parameters(),\n",
    "            lr=self.lr,\n",
    "            eps=self.eps,\n",
    "            weight_decay=self.weight_decay,\n",
    "        )\n",
    "\n",
    "        if self.scheduler_name == \"none\":\n",
    "            return self.optimizer\n",
    "\n",
    "        ### this decreases the learning rate by a factor of gamma every step_size\n",
    "        self.scheduler = MultiStepLR(\n",
    "            self.optimizer,\n",
    "            list(range(0, self.trainer.max_epochs, self.step_size)),\n",
    "            gamma=self.gamma,\n",
    "        )\n",
    "\n",
    "        return [self.optimizer], [{\"scheduler\": self.scheduler, \"interval\": \"epoch\"}]\n",
    "        \n",
    "    #### need to add these two things in case the scheduler is used ####\n",
    "    def lr_scheduler_step(self, scheduler, metric) -> None:\n",
    "        if self.scheduler_name != \"none\":\n",
    "            self.scheduler.step()\n",
    "\n",
    "    def on_epoch_end(self) -> None:\n",
    "        if self.scheduler_name != \"none\":\n",
    "            self.scheduler.step()\n",
    "\n",
    "    def process_batch(self, batch, step: str = \"train\"):\n",
    "        \"\"\"Passes and logs a batch for a given type of step (test, train, validation)\"\"\"\n",
    "        \n",
    "        # get data (batch includes labels, which we don't need)\n",
    "        _, noisy_x = batch\n",
    "\n",
    "        # pass through network\n",
    "        # logits have no activation applied\n",
    "        return self(noisy_x)\n",
    "        \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \"\"\"What do do with a training batch\"\"\"\n",
    "        \n",
    "        return self.process_batch(batch, step=\"train\")\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        '''Validation step (at the end of each epoch)'''\n",
    "        \n",
    "        return self.process_batch(batch, step=\"val\")\n",
    "        \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        \n",
    "        '''Test step is essentially the same as a validation step in this instance'''\n",
    "        return self.process_batch(batch, step=\"test\")\n",
    "\n",
    "    def activation_maps(self, x, depth: int=0) -> np.ndarray:\n",
    "        \n",
    "        '''Gets output activation of an arbitary CNN layer'''\n",
    "        \n",
    "        i = 0\n",
    "        # input layer\n",
    "        x = self.activation(self.input_cnn(x))\n",
    "        \n",
    "        if depth == 0:\n",
    "            return x.detach().numpy()\n",
    "        \n",
    "        i += 1\n",
    "        x = F.max_pool2d(x, 2)\n",
    "            \n",
    "        # pass through CNN and return when you reach the appropriate depth\n",
    "        for layer in self.encoding_layers:\n",
    "            x = self.activation(layer(x))\n",
    "            if i == depth:\n",
    "                return x.detach().numpy()\n",
    "            i += 1\n",
    "            x = F.max_pool2d(x, 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7caf409-ab0a-4df8-b54b-0ed5a4efeae5",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c46f1e2-36bf-4c4c-8071-61079deddf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, \n",
    "                 kernel_size: int = 3, \n",
    "                 dropout: float = 0.25,\n",
    "                 cnn_layer_dims: list = [32, 64, 128],\n",
    "                 padding: int = 1, \n",
    "                 stride: int = 2,\n",
    "                 image_input_channels: int = 1,\n",
    "                 n_input_channels: int = 128,\n",
    "                 input_xy: int = 4, \n",
    "                 lr: float = 1e-4, \n",
    "                 weight_decay: float = 0., \n",
    "                 eps: float = 5e-7, \n",
    "                 activation: torch.nn.modules.activation = F.gelu,\n",
    "                 use_wandb: bool=False,\n",
    "                 scheduler_name: str = \"none\",\n",
    "                 step_size: int = 5,\n",
    "                 gamma: float = 0.5,\n",
    "                 output_padding: int = 1,\n",
    "                 ) -> None:\n",
    "        super().__init__()\n",
    "        ### Always need to call above function first in order\n",
    "        ### to properly initialize a model\n",
    "        '''Basic CNN to classify fashion MNIST\n",
    "        We aren't going to both with some of the fancier stuff from the MLP, but it's easy enough to apply here too\n",
    "        '''\n",
    "        \n",
    "        # model parameters\n",
    "        self.cnn_dims = cnn_layer_dims\n",
    "        self.image_input_channels = image_input_channels\n",
    "        self.activation = activation\n",
    "        self.lr = lr\n",
    "        self.eps = eps\n",
    "        self.weight_decay = weight_decay\n",
    "        self.dropout = dropout\n",
    "        self.n_cnn_layers = len(cnn_layer_dims)\n",
    "        self.scheduler_name = scheduler_name\n",
    "        # if using a scheduler\n",
    "        self.step_size = step_size\n",
    "        self.gamma = gamma\n",
    "        \n",
    "        # log using WandB or TensorBoard\n",
    "        self.use_wandb = use_wandb\n",
    "\n",
    "        # what the input data looks like (allows construction of graph for logging)\n",
    "        # (batch_size, channels, height, width)\n",
    "        self.example_input_array = torch.zeros(\n",
    "            (1, n_input_channels, input_xy, input_xy,),\n",
    "            dtype=torch.float32\n",
    "        )\n",
    "        \n",
    "        #### Construct the layers #####\n",
    "        ## get input layer\n",
    "        ## shape = (C, H, W) -> (cnn_layer_dim, H, W)\n",
    "        self.input_cnn = nn.ConvTranspose2d(n_input_channels,\n",
    "                                            cnn_layer_dims[0], \n",
    "                                            kernel_size=kernel_size, \n",
    "                                            # output_padding=output_padding, \n",
    "                                            padding=padding, stride=stride\n",
    "                                          )\n",
    "\n",
    "        ## make CNN hidden layers\n",
    "        self.decoding_layers = []\n",
    "        for i in range(1, self.n_cnn_layers):\n",
    "\n",
    "            ### ConvTranspose2d __upscales__ the data with output padding\n",
    "            self.decoding_layers.append(nn.ConvTranspose2d(cnn_layer_dims[i-1],\n",
    "                                                           cnn_layer_dims[i], \n",
    "                                                           kernel_size=kernel_size, \n",
    "                                                           output_padding=output_padding, \n",
    "                                                           padding=padding, stride=stride\n",
    "                                                          ))\n",
    "\n",
    "            # self.decoding_layers.append(nn.Conv2d(cnn_layer_dims[i], cnn_layer_dims[i], \n",
    "                                       # kernel_size=kernel_size, stride=stride, padding=padding))\n",
    "\n",
    "        self.decoding_layers.append(nn.ConvTranspose2d(cnn_layer_dims[-1],\n",
    "                                                       self.image_input_channels, \n",
    "                                                       kernel_size=kernel_size, \n",
    "                                                       output_padding=output_padding, \n",
    "                                                       padding=padding, stride=stride,\n",
    "                                                    ))\n",
    "\n",
    "        # self.decoding_layers.append(nn.Tanh())\n",
    "\n",
    "        self.decoding_layers = nn.ModuleList(self.decoding_layers)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self) -> None:\n",
    "        ### does some fancy layer weight initialization\n",
    "        for layer in self.decoding_layers:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                nn.init.xavier_uniform_(layer.weight)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        '''Determines how data is passed through the network, \n",
    "           i.e creates the connectivity of the network'''\n",
    "        ## send through input layer and activate\n",
    "        x = self.activation(self.input_cnn(x))\n",
    "        # pass through CNN\n",
    "        for layer in self.decoding_layers:\n",
    "            # pass through layer\n",
    "            x = layer(x)\n",
    "            x = self.activation(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def configure_optimizers(self) -> (list, list):\n",
    "        \"\"\"Set up the optimizer and potential learning rate scheduler\"\"\"\n",
    "        self.optimizer = torch.optim.AdamW(\n",
    "            self.parameters(),\n",
    "            lr=self.lr,\n",
    "            eps=self.eps,\n",
    "            weight_decay=self.weight_decay,\n",
    "        )\n",
    "\n",
    "        if self.scheduler_name == \"none\":\n",
    "            return self.optimizer\n",
    "\n",
    "        ### this decreases the learning rate by a factor of gamma every step_size\n",
    "        self.scheduler = MultiStepLR(\n",
    "            self.optimizer,\n",
    "            list(range(0, self.trainer.max_epochs, self.step_size)),\n",
    "            gamma=self.gamma,\n",
    "        )\n",
    "\n",
    "        return [self.optimizer], [{\"scheduler\": self.scheduler, \"interval\": \"epoch\"}]\n",
    "        \n",
    "    #### need to add these two things in case the scheduler is used ####\n",
    "    def lr_scheduler_step(self, scheduler, metric) -> None:\n",
    "        if self.scheduler_name != \"none\":\n",
    "            self.scheduler.step()\n",
    "\n",
    "    def on_epoch_end(self) -> None:\n",
    "        if self.scheduler_name != \"none\":\n",
    "            self.scheduler.step()\n",
    "\n",
    "    def process_batch(self, batch, step: str = \"train\"):\n",
    "        \"\"\"Passes and logs a batch for a given type of step (test, train, validation)\"\"\"\n",
    "        \n",
    "        # get data (batch includes labels, which we don't need)\n",
    "        _, noisy_x = batch\n",
    "\n",
    "        # pass through network\n",
    "        # logits have no activation applied\n",
    "        return self(noisy_x)\n",
    "        \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \"\"\"What do do with a training batch\"\"\"\n",
    "        \n",
    "        return self.process_batch(batch, step=\"train\")\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        '''Validation step (at the end of each epoch)'''\n",
    "        \n",
    "        return self.process_batch(batch, step=\"val\")\n",
    "        \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        \n",
    "        '''Test step is essentially the same as a validation step in this instance'''\n",
    "        return self.process_batch(batch, step=\"test\")\n",
    "\n",
    "    def activation_maps(self, x, depth: int=0) -> np.ndarray:\n",
    "        \n",
    "        '''Gets output activation of an arbitary CNN layer'''\n",
    "        \n",
    "        i = 0\n",
    "        # input layer\n",
    "        x = self.activation(self.input_cnn(x))\n",
    "        \n",
    "        if depth == 0:\n",
    "            return x.detach().numpy()\n",
    "        \n",
    "        i += 1\n",
    "        x = F.max_pool2d(x, 2)\n",
    "            \n",
    "        # pass through CNN and return when you reach the appropriate depth\n",
    "        for layer in self.decoding_layers:\n",
    "            x = self.activation(layer(x))\n",
    "            if i == depth:\n",
    "                return x.detach().numpy()\n",
    "            i += 1\n",
    "            x = F.max_pool2d(x, 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9d8a77-00d6-4f76-abc8-df7905b3d743",
   "metadata": {},
   "source": [
    "## Entire network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34768c2-8f0b-4623-8401-2b21c5b182e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, \n",
    "                 kernel_size: int = 3, \n",
    "                 dropout: float = 0.25,\n",
    "                 cnn_layer_dims: list = [128, 64, 32],\n",
    "                 padding: int = 1, \n",
    "                 stride: int = 2,\n",
    "                 image_input_channels: int = 1,\n",
    "                 latent_dim: int = 32,\n",
    "                 input_xy: int = 28, \n",
    "                 lr: float = 1e-4, \n",
    "                 weight_decay: float = 0., \n",
    "                 eps: float = 5e-7, \n",
    "                 activation: torch.nn.modules.activation = F.gelu,\n",
    "                 use_wandb: bool=False,\n",
    "                 scheduler_name: str = \"none\",\n",
    "                 step_size: int = 5,\n",
    "                 gamma: float = 0.5,\n",
    "                 output_padding: int = 1,\n",
    "                 ) -> None:\n",
    "        super().__init__()\n",
    "        ### Always need to call above function first in order\n",
    "        ### to properly initialize a model\n",
    "        '''Basic CNN to classify fashion MNIST\n",
    "        We aren't going to both with some of the fancier stuff from the MLP, but it's easy enough to apply here too\n",
    "        '''\n",
    "        \n",
    "        # model parameters\n",
    "        self.cnn_dims = cnn_layer_dims\n",
    "        self.image_input_channels = image_input_channels\n",
    "        self.activation = activation\n",
    "        self.lr = lr\n",
    "        self.eps = eps\n",
    "        self.weight_decay = weight_decay\n",
    "        self.dropout = dropout\n",
    "        self.n_channels = len(cnn_layer_dims)\n",
    "        self.scheduler_name = scheduler_name\n",
    "        # if using a scheduler\n",
    "        self.step_size = step_size\n",
    "        self.gamma = gamma\n",
    "\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        self.loss_fn = nn.MSELoss()\n",
    "        \n",
    "        # log using WandB or TensorBoard\n",
    "        self.use_wandb = use_wandb\n",
    "\n",
    "        # what the input data looks like (allows construction of graph for logging)\n",
    "        # (batch_size, channels, height, width)\n",
    "        self.example_input_array = torch.zeros(\n",
    "            (1, image_input_channels, input_xy, input_xy,),\n",
    "            dtype=torch.float32\n",
    "        )\n",
    "        \n",
    "\n",
    "        self.encoder = Encoder(\n",
    "                  cnn_layer_dims=cnn_layer_dims, \n",
    "                  input_xy=input_xy, \n",
    "                  activation=activation, \n",
    "                  n_channels=n_channels,\n",
    "                  use_wandb=use_wandb,\n",
    "                  dropout=dropout, \n",
    "                  padding=padding,\n",
    "                  eps=eps, lr=lr, \n",
    "                  weight_decay=weight_decay,\n",
    "                  scheduler_name=scheduler_name,\n",
    "                  gamma=gamma,\n",
    "                  step_size=step_size,\n",
    "        )\n",
    "\n",
    "        # get output dimensions of encoder\n",
    "        self.encoded_cxy, self.flat_dim = self._flat_layer_size()\n",
    "\n",
    "        self.decoder = Decoder(\n",
    "                  cnn_layer_dims=cnn_layer_dims[::-1], \n",
    "                  input_xy=self.encoded_cxy[-1], \n",
    "                  activation=activation, \n",
    "                  n_input_channels=cnn_layer_dims[-1],\n",
    "                  image_input_channels=image_input_channels,\n",
    "                  use_wandb=use_wandb,\n",
    "                  dropout=dropout, \n",
    "                  padding=padding,\n",
    "                  eps=eps, lr=lr, \n",
    "                  weight_decay=weight_decay,\n",
    "                  scheduler_name=scheduler_name,\n",
    "                  gamma=gamma,\n",
    "                  step_size=step_size,\n",
    "                  output_padding=output_padding,\n",
    "        )\n",
    "\n",
    "\n",
    "        self.latent_encoder = nn.Linear(self.flat_dim, self.latent_dim)\n",
    "        self.latent_decoder = nn.Linear(self.latent_dim, self.flat_dim)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self) -> None:\n",
    "        ### does some fancy layer weight initialization\n",
    "        nn.init.xavier_uniform_(self.latent_decoder.weight)\n",
    "        nn.init.xavier_uniform_(self.latent_encoder.weight)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        '''Determines how data is passed through the network, \n",
    "           i.e creates the connectivity of the network'''\n",
    "        \n",
    "        # encode\n",
    "        x = self.encoder(x)\n",
    "\n",
    "        # put into latent space\n",
    "        x = nn.Flatten()(x)\n",
    "        x = self.activation(self.latent_encoder(x))\n",
    "\n",
    "        # bring out of latent space\n",
    "        x = self.activation(self.latent_decoder(x))\n",
    "\n",
    "        # import pdb; pdb.set_trace()\n",
    "\n",
    "        # decode\n",
    "        x = x.reshape(x.shape[0], \n",
    "                      -1, \n",
    "                      self.encoded_cxy[-1], \n",
    "                      self.encoded_cxy[-1])\n",
    "\n",
    "        # import pdb; pdb.set_trace()\n",
    "        \n",
    "        x = self.decoder(x)\n",
    "\n",
    "        # import pdb; pdb.set_trace()\n",
    "\n",
    "        return nn.ReLU()(x)\n",
    "\n",
    "    def configure_optimizers(self) -> (list, list):\n",
    "        \"\"\"Set up the optimizer and potential learning rate scheduler\"\"\"\n",
    "        self.optimizer = torch.optim.AdamW(\n",
    "            self.parameters(),\n",
    "            lr=self.lr,\n",
    "            eps=self.eps,\n",
    "            weight_decay=self.weight_decay,\n",
    "        )\n",
    "\n",
    "        if self.scheduler_name == \"none\":\n",
    "            return self.optimizer\n",
    "\n",
    "        ### this decreases the learning rate by a factor of gamma every step_size\n",
    "        self.scheduler = MultiStepLR(\n",
    "            self.optimizer,\n",
    "            list(range(0, self.trainer.max_epochs, self.step_size)),\n",
    "            gamma=self.gamma,\n",
    "        )\n",
    "\n",
    "        return [self.optimizer], [{\"scheduler\": self.scheduler, \"interval\": \"epoch\"}]\n",
    "        \n",
    "    #### need to add these two things in case the scheduler is used ####\n",
    "    def lr_scheduler_step(self, scheduler, metric) -> None:\n",
    "        if self.scheduler_name != \"none\":\n",
    "            self.scheduler.step()\n",
    "\n",
    "    def on_epoch_end(self) -> None:\n",
    "        if self.scheduler_name != \"none\":\n",
    "            self.scheduler.step()\n",
    "\n",
    "    def process_batch(self, batch, step: str = \"train\"):\n",
    "        \"\"\"Passes and logs a batch for a given type of step (test, train, validation)\"\"\"\n",
    "        \n",
    "        # get data (batch includes labels, which we don't need)\n",
    "        x, noisy_x = batch\n",
    "\n",
    "        # pass through network\n",
    "        denoised_x = self(noisy_x)\n",
    "\n",
    "        # flatten to get easy MSE\n",
    "        denoised_x = nn.Flatten()(denoised_x)\n",
    "        x = nn.Flatten()(x)\n",
    "\n",
    "        # import pdb; pdb.set_trace()\n",
    "        \n",
    "        loss = self.loss_fn(x, denoised_x)\n",
    "\n",
    "        self.log(f\"{step}_loss\", loss)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \"\"\"What do do with a training batch\"\"\"\n",
    "        \n",
    "        return self.process_batch(batch, step=\"train\")\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        '''Validation step (at the end of each epoch)'''\n",
    "        \n",
    "        return self.process_batch(batch, step=\"val\")\n",
    "        \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        \n",
    "        '''Test step is essentially the same as a validation step in this instance'''\n",
    "        return self.process_batch(batch, step=\"test\")\n",
    "\n",
    "    def _flat_layer_size(self) -> int:\n",
    "        \n",
    "        '''Gets the dimension of the flattened CNN output layer'''\n",
    "        \n",
    "        x = self.example_input_array\n",
    "        \n",
    "        # Pass the input tensor through the CNN layers\n",
    "        x = self.encoder(x)\n",
    "\n",
    "        array_dim = x.size()\n",
    "        # Calculate the flattened layer dimension\n",
    "        flattened_dim = x.view(1, -1).size(1)\n",
    "\n",
    "        return array_dim, flattened_dim\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef01ded2-09ea-44bb-bbff-ed413b806860",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181cff3d-1554-474d-bb59-3c007845f0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model hyper parameters \n",
    "lr = 1e-3\n",
    "eps = 1e-8\n",
    "weight_decay = 1e-6\n",
    "dropout = 0.25\n",
    "cnn_layer_dims  = [128,]\n",
    "n_cnn_layers = len(cnn_layer_dims)\n",
    "latent_dim = 16\n",
    "activation = F.gelu\n",
    "n_channels = 1\n",
    "stride = 2\n",
    "kernel_size = 3\n",
    "padding = 0\n",
    "output_padding = 1\n",
    "scheduler_name = \"none\"\n",
    "gamma = 0.5\n",
    "step_size = 5\n",
    "\n",
    "## WandB stuff\n",
    "# log with WandB or TensorBoard\n",
    "use_wandb = False\n",
    "# do hyperparameter sweep with WandB\n",
    "use_sweep = False\n",
    "# WandB project name\n",
    "project_name = 'FashionMNIST_AE'\n",
    "# WandB lab name\n",
    "entity = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3dcfd0-39cc-43c2-806f-be7df9ce685a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Autoencoder(latent_dim=latent_dim,\n",
    "                  cnn_layer_dims=cnn_layer_dims, \n",
    "                  input_xy=input_xy, \n",
    "                  activation=activation, \n",
    "                  image_input_channels=n_channels,\n",
    "                  use_wandb=use_wandb,\n",
    "                  dropout=dropout, \n",
    "                  eps=eps, \n",
    "                  lr=lr, \n",
    "                  weight_decay=weight_decay,\n",
    "                  scheduler_name=scheduler_name,\n",
    "                  gamma=gamma,\n",
    "                  step_size=step_size,\n",
    "                  stride=stride,\n",
    "                  padding=padding,\n",
    "                  output_padding=output_padding,\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d60d27-f63c-4a92-8561-4ec44df16922",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8bb6a899-eb09-407d-9af0-476bc6f42fbc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23090e19-681d-4286-867b-12598da0ce56",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab58c32-b400-40ab-8eaa-b5a64160bb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "accelerator_name = \"mps\"\n",
    "# accelerator_name = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15ca5fe-8bd4-4e27-91e1-f35cb533df8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# boilerplate to get GPU if possible\n",
    "if accelerator_name == \"mps\":\n",
    "    device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "elif accelerator_name == \"cuda\":\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "# Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "torch.backends.cudnn.determinstic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fa5dfc-45e3-4f06-9b69-1f3d261a65f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fcca20-f958-4675-8659-e9d68ebaa791",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not use_wandb:\n",
    "    %load_ext tensorboard\n",
    "    cnn_logger = TensorBoardLogger(\"ae_logs\", name=\"simple_mnist_fashion_ae\")\n",
    "    run_name = \"ae_cnn\"\n",
    "else:\n",
    "    logger_kwargs = {\n",
    "        \"resume\": \"allow\",\n",
    "        \"config\": model_hparams,\n",
    "    }\n",
    "    cnn_logger = WandbLogger(project=project_name, entity=entity, **logger_kwargs)\n",
    "    cnn_run_name = cnn_logger.experiment.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf356a7-8b6f-4b19-8a77-4240a247322e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### necessary for newer PTL versions\n",
    "devices = 1\n",
    "accelerator = \"gpu\" if devices == 1 else \"cpu\"\n",
    "\n",
    "# make the trainer\n",
    "trainer = pl.Trainer(\n",
    "    devices=devices,\n",
    "    accelerator=accelerator,\n",
    "    max_epochs=num_epochs,\n",
    "    log_every_n_steps=1,\n",
    "    logger=cnn_logger,\n",
    "    # reload_dataloaders_every_epoch=True,\n",
    "    callbacks=[\n",
    "        # ModelCheckpoint(\n",
    "        #     save_weights_only=False,\n",
    "        #     mode=\"min\",\n",
    "        #     monitor=\"val_acc\",\n",
    "        #     save_top_k=1,\n",
    "        #     every_n_epochs=1,\n",
    "        #     save_on_train_epoch_end=False,\n",
    "        #     dirpath=f\"/AE_Checkpoints/{run_name}/\",\n",
    "        #     filename=f\"ae_checkpoint_{run_name}\",\n",
    "        # ),\n",
    "        LearningRateMonitor(\"epoch\"),\n",
    "        progress.TQDMProgressBar(refresh_rate=1),\n",
    "        EarlyStopping(\n",
    "            monitor=\"val_loss\",\n",
    "            min_delta=0,\n",
    "            patience=10,\n",
    "            verbose=False,\n",
    "            mode=\"min\",\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "trainer.logger._log_graph = True\n",
    "trainer.logger._default_hp_metric = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39e4c9c-946c-4042-8a55-0292cfa27dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c2cb8d-227c-45a2-b100-23800bf3bc42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "94471401-4adb-4fba-a579-2a453569cb87",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e8c71c-c1d1-4ab3-992f-48412ebbcbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get test metrics\n",
    "test_results = trainer.test(model, test_loader)\n",
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08360f9-1b26-41d2-a981-78f861982ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## open up TensorBoard\n",
    "if not use_wandb:\n",
    "    %tensorboard --logdir ae_logs --port 6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb10142f-3634-492b-a770-7c9d15d80735",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee4841c2-4f9f-481d-abb3-34b34fc11281",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Look at images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735c0a72-6b46-4a43-ad72-3e7d3cabe4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting a prameters\n",
    "scale_factor = 1.5\n",
    "\n",
    "labels = 16 * scale_factor\n",
    "ticks = 10 * scale_factor\n",
    "# ticks = 10 * scale_factor\n",
    "legends = 12 * scale_factor\n",
    "text = 14 * scale_factor\n",
    "titles = 22 * scale_factor\n",
    "lw = 3 * scale_factor\n",
    "ps = 200 * scale_factor\n",
    "cmap = 'magma'\n",
    "\n",
    "colors = ['firebrick', 'steelblue', 'darkorange', 'darkviolet', 'cyan', 'magenta', 'darkgreen', 'deeppink']\n",
    "markers = ['x', 'o', '+', '>', '*', 'D', '4']\n",
    "linestyles = ['-', '--', ':', '-.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980120f4-4106-419a-992a-232126aab4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image_panel(images: list, labels: list=[\"Noisy\", \"Denoised\", \"Clean\"], cmap: str='viridis', show_ticks: bool=True):\n",
    "    \n",
    "    '''Plots a 3x1 panel of images'''\n",
    "    \n",
    "    mplrc('xtick', labelsize=ticks) \n",
    "    mplrc('ytick', labelsize=ticks)\n",
    "    mplrc('axes', titlesize=titles)\n",
    "    \n",
    "    fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(16., 12.))\n",
    "    \n",
    "    for (i, image) in enumerate(images):\n",
    "        ax = axs[i]\n",
    "        \n",
    "        ax.imshow(image, cmap=cmap)\n",
    "        if len(labels) > i and labels[i] != '':\n",
    "            ax.set_title(labels[i])\n",
    "            \n",
    "        if not show_ticks:\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "        elif i > 0:\n",
    "            ax.set_yticks([])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d76588-ba7a-4f1f-81b1-7c64eeae70dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Do inference on test set\n",
    "## need to turn into torch tensor first\n",
    "# X_test_infer = torch.from_numpy(X_test).float()\n",
    "X_noisy_test_infer = torch.from_numpy(noisy_X_test).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8e9f50-ea06-47cb-b584-6f57ed83cf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_noisy_pred_tensor = model(X_noisy_test_infer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42d9796-af35-453b-b112-82d2b852c3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_noisy_pred = X_noisy_pred_tensor.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e781f682-2d8a-4f51-9a43-94b26529f3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "plot_image_panel([noisy_X_test[i].squeeze(), X_noisy_pred[i].squeeze(), X_test[i].squeeze()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a95554-feb3-4762-a06e-9262e8f21fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## broke kernel for some reason ##\n",
    "# rand_latent = torch.randn((1, model.latent_dim)).to(device)\n",
    "# decoded_latent = model.latent_encoder(rand_latent)\n",
    "# decoded_latent = nodel.decoder(decoded_latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af97cea2-db26-421e-ba04-d992afc484a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "f8b13074-933b-4878-9865-6724d18e3862",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ef601107-b660-4726-b727-77d0781457b5",
   "metadata": {},
   "source": [
    "# Variational Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79af75e9-d60e-4d6a-805d-a9f612e9715f",
   "metadata": {},
   "source": [
    "Autoencoders learn deterministic mapping into and out of the latent space. VAEs learn *probabilistic* mapping. That is, they learn a latent space distribution (often a normal distribution). The encoder maps into this (learned) distribution, and the decoder samples out of this distribution to give a final result.\n",
    "\n",
    "The extra power here comes from the probabilistic latent space. The network is (hopefully) trained such that any sample from the latent space can be decoded properly. If I put in Gaussian noise into the decoder, I should get something coherent out (like an approximate MNIST image). This allows the generation of an arbitrary number of outputs.\n",
    "\n",
    "<img src=\"imgs/vae.png\" style=\"height:300px\" class=\"center\" alt=\"vae\"/><br>\n",
    "\n",
    "Schematic of VAE. Everything is done probabilistically. The encoder outputs a mean ($\\mu$) and standard deviations ($\\sigma$) that describe a normal distrubtion, sampling outputs from this distrubtion. This is equivalent to sampling latent variables that are passed through the decoder. The decoder takes multiple samples from this latent space and decodes them into the output space. This defines an output *distrubtion*. The training objective for a VAE is to maximize the evidence lower bound (ELBO), which is a lower-bound approximation to the log-likelihood of the data (we use log-likelihood because it turns multiplication into addition). \n",
    "\n",
    "$$\\mathrm{ELBO} = KL[q(z|x) || p(z)] - \\mathbb{E}[log(p(x | z))$$ where\n",
    "\n",
    "$$KL[q(z|x) || p(z)] = \\frac{1}{2} \\left[\\sum_{i = 1}^{D}(\\sigma_{i}^{2} + \\mu_{i}^{2} - log(\\sigma_{i}^{2}) -1)\\right]$$ and $\\mathbb{E}[log(p(x | z))$ represents the reconstruction loss (not MSE!).\n",
    "\n",
    "where $\\sigma_{i}$ and $\\mu_{i}$ are the standard deviation and mean of the normal distrubtion describing the $i^{th}$ component of the latent space. The KL divergence means the divergence of $q(z|x)$ from $p(z)$, i.e., measures the distribution of the latent space given the input and the expected output (assumed normal distribution with $\\mu = 0$ and $\\sigma = 1$). This encourages the encoder to approximate a standard normal distrubtion while giving it the freedom to add some minor adjustments.\n",
    "\n",
    "After training, we can simple feed Gaussian noise into the decoder to generate novel samples. This is the first example of generative networks that we have seen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e52e014-0c89-43a0-b32e-e7ce32414b81",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1e4f24-b267-409d-ae3c-397e0d2a89e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kl_divergence(z: torch.Tensor, mu: torch.Tensor, sigma: torch.Tensor) -> float:\n",
    "    \"\"\"This calculates the KL divergence\"\"\"\n",
    "\n",
    "    return 0.5 * (sigma ** 2 + mu ** 2 - torch.log(sigma) - 1.).sum()\n",
    "\n",
    "\n",
    "def get_reconstruction_loss(x: torch.Tensor, decoded_x: torch.Tensor, epsilon: nn.Parameter) -> torch.Tensor:\n",
    "    \"\"\"Gets reconstruction loss of latent space from a standard distrubtion\"\"\"\n",
    "\n",
    "    # get predicted distribtion\n",
    "    exp_scale = torch.exp(epsilon)\n",
    "    dist = torch.distributions.Normal(decoded_x, exp_scale)\n",
    "\n",
    "    # measure get p(x|z) using the predicted distribution\n",
    "    log_pxz = dist.log_prob(x)\n",
    "    \n",
    "    return log_pxz.sum(dim=(1, 2, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c1ef42-278d-4944-bb9e-4e2b4b4272c1",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7903dc85-5adb-4440-be1a-fb6b6aa6bd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariationalAutoencoder(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, \n",
    "                 kernel_size: int = 3, \n",
    "                 dropout: float = 0.25,\n",
    "                 cnn_layer_dims: list = [128, 64, 32],\n",
    "                 padding: int = 1, \n",
    "                 stride: int = 2,\n",
    "                 image_input_channels: int = 1,\n",
    "                 latent_dim: int = 32,\n",
    "                 input_xy: int = 28, \n",
    "                 lr: float = 1e-4, \n",
    "                 weight_decay: float = 0., \n",
    "                 eps: float = 5e-7, \n",
    "                 activation: torch.nn.modules.activation = F.gelu,\n",
    "                 use_wandb: bool=False,\n",
    "                 scheduler_name: str = \"none\",\n",
    "                 step_size: int = 5,\n",
    "                 gamma: float = 0.5,\n",
    "                 output_padding: int = 1,\n",
    "                 ) -> None:\n",
    "        super().__init__()\n",
    "        ### Always need to call above function first in order\n",
    "        ### to properly initialize a model\n",
    "        '''Basic CNN to classify fashion MNIST\n",
    "        We aren't going to both with some of the fancier stuff from the MLP, but it's easy enough to apply here too\n",
    "        '''\n",
    "        \n",
    "        # model parameters\n",
    "        self.cnn_dims = cnn_layer_dims\n",
    "        self.image_input_channels = image_input_channels\n",
    "        self.activation = activation\n",
    "        self.lr = lr\n",
    "        self.eps = eps\n",
    "        self.weight_decay = weight_decay\n",
    "        self.dropout = dropout\n",
    "        self.n_channels = len(cnn_layer_dims)\n",
    "        self.scheduler_name = scheduler_name\n",
    "        # if using a scheduler\n",
    "        self.step_size = step_size\n",
    "        self.gamma = gamma\n",
    "\n",
    "        # standard normal (attempted p(z))\n",
    "        self.normal_distribtion = torch.distributions.Normal(0., 1.)\n",
    "\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        # log using WandB or TensorBoard\n",
    "        self.use_wandb = use_wandb\n",
    "\n",
    "        # what the input data looks like (allows construction of graph for logging)\n",
    "        # (batch_size, channels, height, width)\n",
    "        self.example_input_array = torch.zeros(\n",
    "            (1, image_input_channels, input_xy, input_xy,),\n",
    "            dtype=torch.float32\n",
    "        )\n",
    "        \n",
    "\n",
    "        # we still use our old encoder/decoder\n",
    "        self.encoder = Encoder(\n",
    "                  cnn_layer_dims=cnn_layer_dims, \n",
    "                  input_xy=input_xy, \n",
    "                  activation=activation, \n",
    "                  n_channels=n_channels,\n",
    "                  use_wandb=use_wandb,\n",
    "                  dropout=dropout, \n",
    "                  padding=padding,\n",
    "                  eps=eps, lr=lr, \n",
    "                  weight_decay=weight_decay,\n",
    "                  scheduler_name=scheduler_name,\n",
    "                  gamma=gamma,\n",
    "                  step_size=step_size,\n",
    "        )\n",
    "\n",
    "        # get output dimensions of encoder\n",
    "        self.encoded_cxy, self.flat_dim = self._flat_layer_size()\n",
    "\n",
    "        self.decoder = Decoder(\n",
    "                  cnn_layer_dims=cnn_layer_dims[::-1], \n",
    "                  input_xy=self.encoded_cxy[-1], \n",
    "                  activation=activation, \n",
    "                  n_input_channels=cnn_layer_dims[-1],\n",
    "                  image_input_channels=image_input_channels,\n",
    "                  use_wandb=use_wandb,\n",
    "                  dropout=dropout, \n",
    "                  padding=padding,\n",
    "                  eps=eps, lr=lr, \n",
    "                  weight_decay=weight_decay,\n",
    "                  scheduler_name=scheduler_name,\n",
    "                  gamma=gamma,\n",
    "                  step_size=step_size,\n",
    "                  output_padding=output_padding,\n",
    "        )\n",
    "\n",
    "\n",
    "        self.mu = nn.Linear(self.flat_dim, self.latent_dim)\n",
    "        self.sigma = nn.Linear(self.flat_dim, self.latent_dim)\n",
    "        self.epsilon = nn.Parameter(torch.Tensor([0.]))\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self) -> None:\n",
    "        ### does some fancy layer weight initialization\n",
    "        nn.init.xavier_uniform_(self.mu.weight)\n",
    "        nn.init.xavier_uniform_(self.sigma.weight)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        '''Determines how data is passed through the network, \n",
    "           i.e creates the connectivity of the network'''\n",
    "        \n",
    "        # encode\n",
    "        x = self.encoder(x)\n",
    "\n",
    "        # put into latent space\n",
    "        x = nn.Flatten()(x)\n",
    "\n",
    "        # get distribution of latent space\n",
    "        mu_hat = self.mu(x)\n",
    "        sigma_hat = torch.exp(self.sigma(x))\n",
    "\n",
    "        # decode\n",
    "        x = x.reshape(x.shape[0], \n",
    "                      -1, \n",
    "                      self.encoded_cxy[-1], \n",
    "                      self.encoded_cxy[-1])\n",
    "\n",
    "        # import pdb; pdb.set_trace()\n",
    "        \n",
    "        x = self.decoder(x)\n",
    "        return nn.ReLU()(x), mu_hat, sigma_hat\n",
    "\n",
    "    def configure_optimizers(self) -> (list, list):\n",
    "        \"\"\"Set up the optimizer and potential learning rate scheduler\"\"\"\n",
    "        self.optimizer = torch.optim.AdamW(\n",
    "            self.parameters(),\n",
    "            lr=self.lr,\n",
    "            eps=self.eps,\n",
    "            weight_decay=self.weight_decay,\n",
    "        )\n",
    "\n",
    "        if self.scheduler_name == \"none\":\n",
    "            return self.optimizer\n",
    "\n",
    "        ### this decreases the learning rate by a factor of gamma every step_size\n",
    "        self.scheduler = MultiStepLR(\n",
    "            self.optimizer,\n",
    "            list(range(0, self.trainer.max_epochs, self.step_size)),\n",
    "            gamma=self.gamma,\n",
    "        )\n",
    "\n",
    "        return [self.optimizer], [{\"scheduler\": self.scheduler, \"interval\": \"epoch\"}]\n",
    "        \n",
    "    #### need to add these two things in case the scheduler is used ####\n",
    "    def lr_scheduler_step(self, scheduler, metric) -> None:\n",
    "        if self.scheduler_name != \"none\":\n",
    "            self.scheduler.step()\n",
    "\n",
    "    def on_epoch_end(self) -> None:\n",
    "        if self.scheduler_name != \"none\":\n",
    "            self.scheduler.step()\n",
    "\n",
    "    def process_batch(self, batch, step: str = \"train\"):\n",
    "        \"\"\"Passes and logs a batch for a given type of step (test, train, validation)\"\"\"\n",
    "        \n",
    "        # get data (batch includes labels, which we don't need)\n",
    "        x, _ = batch\n",
    "\n",
    "        # pass through network\n",
    "        x_pred, mu_hat, sigma_hat = self(x)\n",
    "\n",
    "        # get latent variables\n",
    "        z = mu_hat + sigma_hat * self.normal_distribtion.sample(mu_hat.shape).to(self.device)\n",
    "\n",
    "        recon_loss = get_reconstruction_loss(x, x_pred, self.epsilon).mean()\n",
    "        kl_divergence = get_kl_divergence(z, mu_hat, sigma_hat)\n",
    "\n",
    "        loss = kl_divergence - recon_loss\n",
    "\n",
    "        self.log(f\"{step}_loss\", loss)\n",
    "        self.log(f\"{step}_avg_reconstruction_loss\", recon_loss)\n",
    "        self.log(f\"{step}_kl_divergence\", kl_divergence)\n",
    "        self.log(f\"{step}_avg_mu\", mu_hat.mean())\n",
    "        self.log(f\"{step}_avg_sigma\", sigma_hat.mean())\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \"\"\"What do do with a training batch\"\"\"\n",
    "        \n",
    "        return self.process_batch(batch, step=\"train\")\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        '''Validation step (at the end of each epoch)'''\n",
    "        \n",
    "        return self.process_batch(batch, step=\"val\")\n",
    "        \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        \n",
    "        '''Test step is essentially the same as a validation step in this instance'''\n",
    "        return self.process_batch(batch, step=\"test\")\n",
    "\n",
    "    def _flat_layer_size(self) -> int:\n",
    "        \n",
    "        '''Gets the dimension of the flattened CNN output layer'''\n",
    "        \n",
    "        x = self.example_input_array\n",
    "        \n",
    "        # Pass the input tensor through the CNN layers\n",
    "        x = self.encoder(x)\n",
    "\n",
    "        array_dim = x.size()\n",
    "        # Calculate the flattened layer dimension\n",
    "        flattened_dim = x.view(1, -1).size(1)\n",
    "\n",
    "        return array_dim, flattened_dim\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265a3839-81db-4479-90c4-9d7e4ec4d55e",
   "metadata": {},
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128731a0-fe89-4316-89ef-3fb81e44b999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model hyper parameters \n",
    "lr = 5e-4\n",
    "eps = 1e-8\n",
    "weight_decay = 1e-7\n",
    "dropout = 0.25\n",
    "cnn_layer_dims  = [128,]\n",
    "n_cnn_layers = len(cnn_layer_dims)\n",
    "latent_dim = 32\n",
    "activation = F.gelu\n",
    "n_channels = 1\n",
    "stride = 2\n",
    "kernel_size = 3\n",
    "padding = 0\n",
    "output_padding = 1\n",
    "scheduler_name = \"step\"\n",
    "gamma = 0.5\n",
    "step_size = 5\n",
    "\n",
    "## WandB stuff\n",
    "# log with WandB or TensorBoard\n",
    "use_wandb = False\n",
    "# do hyperparameter sweep with WandB\n",
    "use_sweep = False\n",
    "# WandB project name\n",
    "project_name = 'FashionMNIST_VAE'\n",
    "# WandB lab name\n",
    "entity = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28b3149-62d9-4200-8ad7-e0a7ca0177e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_model = VariationalAutoencoder(latent_dim=latent_dim,\n",
    "                  cnn_layer_dims=cnn_layer_dims, \n",
    "                  input_xy=input_xy, \n",
    "                  activation=activation, \n",
    "                  image_input_channels=n_channels,\n",
    "                  use_wandb=use_wandb,\n",
    "                  dropout=dropout, \n",
    "                  eps=eps, \n",
    "                  lr=lr, \n",
    "                  weight_decay=weight_decay,\n",
    "                  scheduler_name=scheduler_name,\n",
    "                  gamma=gamma,\n",
    "                  step_size=step_size,\n",
    "                  stride=stride,\n",
    "                  padding=padding,\n",
    "                  output_padding=output_padding,\n",
    "               )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d1e623-010b-4bbc-8fe6-2e9c8cf0ea32",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406fb799-ba31-49b6-be22-cdefad32463e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8242d068-da74-49cf-a851-c5589af1cf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "accelerator_name = \"mps\"\n",
    "# accelerator_name = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77a820a-7bad-4647-99dd-82fbabff95f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# boilerplate to get GPU if possible\n",
    "if accelerator_name == \"mps\":\n",
    "    device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "elif accelerator_name == \"cuda\":\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "# Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "torch.backends.cudnn.determinstic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7b73b9-571f-4f01-a551-38f145142074",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_model = vae_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6729aad4-5aa1-400b-928d-04a7750c0cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fab0e8-2ab0-4645-8b51-a65038bfe2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not use_wandb:\n",
    "    %load_ext tensorboard\n",
    "    vae_logger = TensorBoardLogger(\"vae_logs\", name=\"simple_mnist_fashion_vae\")\n",
    "    run_name = \"vae_cnn\"\n",
    "else:\n",
    "    logger_kwargs = {\n",
    "        \"resume\": \"allow\",\n",
    "        \"config\": model_hparams,\n",
    "    }\n",
    "    vae_logger = WandbLogger(project=project_name, entity=entity, **logger_kwargs)\n",
    "    vae_run_name = vae_logger.experiment.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08acbadf-fd8e-47fb-b263-b7f0036604e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### necessary for newer PTL versions\n",
    "devices = 1\n",
    "accelerator = \"cpu\" if device.type == \"cpu\" else \"gpu\"\n",
    "\n",
    "# make the trainer\n",
    "vae_trainer = pl.Trainer(\n",
    "    devices=devices,\n",
    "    accelerator=accelerator,\n",
    "    max_epochs=num_epochs,\n",
    "    log_every_n_steps=1,\n",
    "    logger=vae_logger,\n",
    "    # reload_dataloaders_every_epoch=True,\n",
    "    callbacks=[\n",
    "        # ModelCheckpoint(\n",
    "        #     save_weights_only=False,\n",
    "        #     mode=\"min\",\n",
    "        #     monitor=\"val_acc\",\n",
    "        #     save_top_k=1,\n",
    "        #     every_n_epochs=1,\n",
    "        #     save_on_train_epoch_end=False,\n",
    "        #     dirpath=f\"/AE_Checkpoints/{run_name}/\",\n",
    "        #     filename=f\"ae_checkpoint_{run_name}\",\n",
    "        # ),\n",
    "        LearningRateMonitor(\"epoch\"),\n",
    "        progress.TQDMProgressBar(refresh_rate=1),\n",
    "        EarlyStopping(\n",
    "            monitor=\"val_loss\",\n",
    "            min_delta=0,\n",
    "            patience=10,\n",
    "            verbose=False,\n",
    "            mode=\"min\",\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "vae_trainer.logger._log_graph = True\n",
    "vae_trainer.logger._default_hp_metric = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e42c144-96a5-4551-9f00-2739cc1a594e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_trainer.fit(vae_model, train_dataloaders=train_loader, val_dataloaders=val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456d2ab7-0352-406a-b8b6-b07f6449b458",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f05e78c4-690e-408f-bcaf-6ac83b08af12",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e425c4c-7247-4622-99ff-1c4acab34f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get test metrics\n",
    "vae_test_results = vae_trainer.test(vae_model, test_loader)\n",
    "print(vae_test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a0afb6-61b6-4327-96c4-dd920224ac32",
   "metadata": {},
   "outputs": [],
   "source": [
    "## open up TensorBoard\n",
    "if not use_wandb:\n",
    "    %tensorboard --logdir vae_logs --port 6008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81081204-52be-47de-ac92-0660a6412c74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "92176d09-de4b-434c-b7cf-940c5c5c2a4b",
   "metadata": {},
   "source": [
    "## Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d473cbc-5cf5-4cc2-b7a1-b971e365dca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_input = torch.randn(vae_model.encoded_cxy).float()#.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8788f32e-574b-44c3-8389-9c7388d2c7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_output = vae_model.decoder(random_input).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7e2000-b263-4e7c-a81b-15369db2403e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(random_output.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3b8d11-bdea-4b99-bfff-bee3b39c4141",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
