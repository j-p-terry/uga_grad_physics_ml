{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e172863-fd82-4e85-8145-a3fd4c1b46fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Math, Latex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb73c562-a44d-46ca-830f-d8167dc137cf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Some parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e29d0354-e1a2-46b1-b465-1c98201d476d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting a prameters\n",
    "scale_factor = 1.5\n",
    "\n",
    "labels = 16 * scale_factor\n",
    "ticks = 10 * scale_factor\n",
    "# ticks = 10 * scale_factor\n",
    "legends = 12 * scale_factor\n",
    "text = 14 * scale_factor\n",
    "titles = 22 * scale_factor\n",
    "lw = 3 * scale_factor\n",
    "ps = 200 * scale_factor\n",
    "cmap = 'magma'\n",
    "\n",
    "colors = ['firebrick', 'steelblue', 'darkorange', 'darkviolet', 'cyan', 'magenta', 'darkgreen', 'deeppink']\n",
    "markers = ['x', 'o', '+', '>', '*', 'D', '4']\n",
    "linestyles = ['-', '--', ':', '-.']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde43a97-ef1d-4660-95f9-50b513ef26ef",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Some functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e3b7ef1-f8a4-43b2-b9da-f34148a385ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm \n",
    "from matplotlib import rc as mplrc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86484ef1-15e3-4c1a-84bd-07aef58dfe89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(image: list, category: str='', cmap: str='viridis', show_ticks: bool=True):\n",
    "    \n",
    "    '''Plots an image'''\n",
    "    \n",
    "    plt.figure(figsize=(8.5, 8.))\n",
    "    \n",
    "    plt.imshow(image, cmap=cmap)\n",
    "    \n",
    "    if show_ticks:\n",
    "        plt.xticks(fontsize=ticks)\n",
    "        plt.yticks(fontsize=ticks)\n",
    "    else:\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        \n",
    "    if category != '':\n",
    "        plt.title(category, fontsize=titles)\n",
    "        \n",
    "    plt.show()\n",
    "    \n",
    "def plot_image_panel(images: list, labels: list=[], cmap: str='viridis', show_ticks: bool=True):\n",
    "    \n",
    "    '''Plots a 2x2 panel of images'''\n",
    "    \n",
    "    mplrc('xtick', labelsize=ticks) \n",
    "    mplrc('ytick', labelsize=ticks)\n",
    "    mplrc('axes', titlesize=titles)\n",
    "    \n",
    "    fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(12., 12.))\n",
    "    \n",
    "    for (i, image) in enumerate(images):\n",
    "        if i > 1:\n",
    "            ax = axs[1, i % 2]\n",
    "        else:\n",
    "            ax = axs[0, i]\n",
    "        \n",
    "        ax.imshow(image, cmap=cmap)\n",
    "        if len(labels) > i and labels[i] != '':\n",
    "            ax.set_title(labels[i])\n",
    "        if i % 2 == 1:\n",
    "            ax.set_yticks([])\n",
    "            ax.set_yticks([])\n",
    "    \n",
    "        if not show_ticks:\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "        \n",
    "    plt.show()\n",
    "\n",
    "def plot_curves(curves: list, plot_labels: list=[], cmap: str='viridis', show_ticks: bool=True, \n",
    "                xlabel: str='x', ylabel: str='y', xscale: str='', yscale: str=''):\n",
    "    \n",
    "    '''Plots multiple curves on the same plot'''\n",
    "    \n",
    "    mplrc('xtick', labelsize=ticks) \n",
    "    mplrc('ytick', labelsize=ticks)\n",
    "    mplrc('axes', titlesize=titles)\n",
    "    \n",
    "    if len(curves) > len(colors):\n",
    "        these_colors = cm.get_cmap('viridis', len(curves)).colors\n",
    "    else:\n",
    "        these_colors = colors\n",
    "    \n",
    "    fig = plt.figure(figsize=(8., 6.))\n",
    "    \n",
    "    for (i, curve) in enumerate(curves):\n",
    "        \n",
    "        plt.plot(curve[0], curve[1], lw=lw, c=colors[i], label=plot_labels[i])\n",
    "        \n",
    "    plt.legend(loc='best', fontsize=legends)\n",
    "    plt.xlabel(xlabel, fontsize=labels)\n",
    "    plt.ylabel(ylabel, fontsize=labels)\n",
    "    plt.xticks(fontsize=ticks)\n",
    "    plt.yticks(fontsize=ticks)\n",
    "    \n",
    "    if xscale == 'log':\n",
    "        plt.xscale('log')\n",
    "    if yscale == 'log':\n",
    "        plt.yscale('log')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def plot_activations(objective: str='regression', alpha: float=1.):\n",
    "\n",
    "    \n",
    "    xs = np.linspace(-4, 4, 100)\n",
    "    \n",
    "    if objective == 'regression':\n",
    "        \n",
    "        relu_ = np.array([get_relu(x) for x in xs])\n",
    "        elu_ = np.array([get_elu(x, alpha=alpha) for x in xs])\n",
    "        silu_ = np.array([get_silu(x) for x in xs])\n",
    "        gelu_ = np.array([get_gelu(x) for x in xs])\n",
    "        \n",
    "        curves = [[xs, relu_], [xs, elu_], [xs, silu_], [xs, gelu_]]\n",
    "        plot_labels = ['ReLU', 'ELU', 'SiLU', 'GELU']\n",
    "        \n",
    "    else:\n",
    "        sigmoid_ = np.array([get_sigmoid(x) for x in xs])\n",
    "        tanh_ = np.array([np.tanh(x) for x in xs])\n",
    "        curves = [[xs, sigmoid_], [xs, tanh_]]\n",
    "        plot_labels = ['Sigmoid', 'tanh']\n",
    "        \n",
    "    \n",
    "    plot_curves(curves, plot_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38d76c0-64d0-489f-ac54-bdbfa3728b4a",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network (CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef41e88d-fd15-449a-85c4-9c444f84238d",
   "metadata": {},
   "source": [
    "CNNs (convolutional neural networks) are designed to process images in a way similar to mammalian brains. They are the bread and butter of computer vision, but models such as vision transformers are becomming increasingly useful and common (more on that later).\n",
    "\n",
    "<img src=\"imgs/cnn.png\" style=\"height:600px\" class=\"center\" alt=\"cnn\"/><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7187fc0-f3a7-45e7-84c4-aef294ddfccd",
   "metadata": {},
   "source": [
    "#### Vanilla CNN overview\n",
    "\n",
    "The basic idea is that a \"kernel\" slides across an image and convolves the pixels that it currently covers (i.e. unravels kernel and pixels and takes dot product). After the entire image has been convolved, it is then activated and pooled to reduce the dimension. A typical pooling procedire is to return the maximum of a 2x2 block. Each convolutional layer has multiple \"channels\" each of which have different kernels. The point of trianing is to get a set of kernels that can effectively analyze the image. One kernel may look at edges, another at corners, etc.\n",
    "\n",
    "After this has been done some number of times, the output is flattened into a N-dimensional vector. This vector is then fed through a typical multilayer perceptron (MLP), which is just a normal neural network. Depending on the problem, this may output a vector representing the class of the input (classification) or a simple numerical vector (regression)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d1514c-a274-4063-a68f-88c5e609d799",
   "metadata": {},
   "source": [
    "[Demo](https://adamharley.com/nn_vis/cnn/2d.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb17d0c-6508-4577-a7b1-995a77449e29",
   "metadata": {},
   "source": [
    "#### Advanced CNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64319a1e-abb5-4f76-a558-ffbd16fac327",
   "metadata": {},
   "source": [
    "While this simple view of convolutions has been very successful, current ML problems are often too complex for them. This has led to the introduction of more advanced methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d447eca-6ab5-45d4-847a-9f461fe3c0dd",
   "metadata": {},
   "source": [
    "##### Residual Blocks (ResNet)\n",
    "\n",
    "<div>\n",
    "<img src=\"imgs/residual-block.svg\" width=\"500\" style=\"display=block; margin:auto\" align=\"center\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a485839-0b90-4096-bf53-b22cb1d5f7d2",
   "metadata": {},
   "source": [
    "Residual blocks have been shown to be one of the most powerful additions to CNNs, and essentially all models now use them to some extent. [ResNet](https://arxiv.org/abs/1512.03385) was the original model that introduced them.\n",
    "\n",
    "The basic idea is that a layer is input through a typical convolutional block while at the same time being added, unchanged, to the resulting output. This more or less allows the network to learn the identity matrix (i.e. $g(\\textbf{x}) = 0$), which can speed up training and convergence.\n",
    "\n",
    "There has been a lot of development in the specifics of residual blocks, and they have been combined with other architectures such as transformers (ConvNext), but the basic idea was the core insight."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a08a41-98d4-42d4-b9a3-df4eebe58c55",
   "metadata": {},
   "source": [
    "##### Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0ac712-4175-450c-92b3-25b2e5892e40",
   "metadata": {},
   "source": [
    "Transformers are relatively new (introduced in [2017](https://arxiv.org/abs/1706.03762)) and were originally designed for natural language processing. They are a qualitatively different type of arthitecture that dispenses with recurrence and uses self-attention. This comes with many benefits including parallel assessment of the sequence and a much more thorough global analysis of the relations between inputs. Recurrent neural networks are more or less obsolete at this point. Everything is a transformer.\n",
    "\n",
    "<div>\n",
    "<img src=\"imgs/transformer.png\" width=\"500\" style=\"display=block; margin:auto\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2df1963-0454-433a-b6d2-0e2d53717ec6",
   "metadata": {},
   "source": [
    "In [2020](https://arxiv.org/abs/2010.11929), it was realized that the same concept can be applied to images. This was the introduction of the vision transformer (ViT). The image is broken up into patches that are passed through a normal transformer. This brings the global benefits analysis benefits of a normal transformer and significantly reduces computational requirements. Vision transformers are probably the future. \n",
    "\n",
    "\n",
    "They are much more complicated conceptually than CNNs, so we won't go into them any further. For now. We probably will after language models (i.e. the original transformer)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfaee9c5-0b24-4b95-962f-18db2305ac98",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"imgs/vit.png\" width=\"1000\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772efd76-21c9-4129-9eca-c5013f8650cc",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31e9b182-85da-4265-89d9-23811915f339",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import PIL\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint, progress\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.loggers import WandbLogger, TensorBoardLogger\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torch.utils.data import DataLoader, Dataset, RandomSampler, random_split\n",
    "\n",
    "import torchmetrics\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc1366cb-c78f-4407-8a79-eee664921b54",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m### Set seed for reproducibility\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;241m123\u001b[39m)\n\u001b[1;32m      3\u001b[0m random\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;241m123\u001b[39m)\n\u001b[1;32m      4\u001b[0m torch\u001b[38;5;241m.\u001b[39mmanual_seed(\u001b[38;5;241m123\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "### Set seed for reproducibility\n",
    "np.random.seed(123)\n",
    "random.seed(123)\n",
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f111d8c-9c9d-4a38-8a0a-006cd22f4d2c",
   "metadata": {},
   "source": [
    "## Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5e5d91-465c-4ca9-8061-fb8567295a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Download fashion MNIST\n",
    "train_dataset = datasets.FashionMNIST(\n",
    "    root='./data', train=True, download=True,)\n",
    "test_dataset = datasets.FashionMNIST(\n",
    "    root='./data', train=False, download=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e3ab5f-ea7c-4cd2-b54b-680a4ab05d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get possible classes in data\n",
    "classes = train_dataset.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0dd70a-12e3-495e-ac58-c2e96a469ac3",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790117bf-680c-424f-9b63-88c1d404eccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_dataset.data.detach().numpy()\n",
    "y_train = train_dataset.targets.detach().numpy()\n",
    "\n",
    "X_test = test_dataset.data.detach().numpy()\n",
    "y_test = test_dataset.targets.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d16471-2385-4ef9-b2ae-a4efb4797712",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PyTorch uses Dataset objects to load the data during training and testing\n",
    "class MNISTDataset(Dataset):\n",
    "\n",
    "    \"\"\"Data set\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        X, y, transforms: list=None, is_train: bool=False\n",
    "    ):\n",
    "        '''Assign data'''\n",
    "        self.X, self.y = X, y\n",
    "        self.transforms = transforms\n",
    "        self.is_train = is_train\n",
    "        \n",
    "    def __len__(self):\n",
    "        '''function to get the length of the dataset'''\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        '''return an x, y pair'''\n",
    "        x_, y_ = self.X[idx], self.y[idx]\n",
    "        \n",
    "        return torch.from_numpy(x_).float(), y_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c780332-d99f-46bf-a146-4bf8095cefea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into validation and training data\n",
    "val_split = 0.2\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, \n",
    "                                                     test_size=val_split,\n",
    "                                                     random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63ea9a8-a0da-47f2-8cb3-f1f90166a49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add channel axes (N, H, W) -> (N, C, H, W) because C = 1 in this case\n",
    "X_train = X_train[:, np.newaxis, :, :]\n",
    "X_test = X_test[:, np.newaxis, :, :]\n",
    "X_val = X_val[:, np.newaxis, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15c5a2b-f67d-4849-a719-bb38e23ce7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get H = W\n",
    "input_xy = X_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b995c984-2c22-45a6-b20a-173128ca4122",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fbd114-01a0-449b-aec2-57698c3278ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Now we actually make the dataset and dataloader in PyTorch fashion\n",
    "train_data = MNISTDataset(X_train, y_train, is_train=True,)\n",
    "val_data = MNISTDataset(X_val, y_val)\n",
    "test_data = MNISTDataset(X_test, y_test)\n",
    "\n",
    "# make the loader\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0faa6565-4a3b-44ff-a74c-b230187ca902",
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot some data\n",
    "plot_classes = [classes[y_train[i]] for i in range(4)]\n",
    "plot_image_panel(X_train[:4, 0], labels=plot_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7fdfae-4418-415d-aed6-b492046e0e04",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99994cf2-ccf7-4844-b794-4ab188661dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, \n",
    "                 n_cnn_layers: int = 3, \n",
    "                 n_mlp_layers: int = 2,\n",
    "                 kernel_size: int = 3, \n",
    "                 dropout: float = 0.25,\n",
    "                 cnn_layer_dim: int = 64,\n",
    "                 mlp_layer_dim: int = 128,\n",
    "                 padding: int = 0, \n",
    "                 stride: int = 1,\n",
    "                 n_classes: int = 10, \n",
    "                 n_channels: int = 1,\n",
    "                 input_xy: int = 28, \n",
    "                 lr: float = 1e-4, \n",
    "                 weight_decay: float = 0., \n",
    "                 eps: float = 5e-7, \n",
    "                 activation: torch.nn.functional=F.relu,\n",
    "                 use_wandb: bool=False,\n",
    "                 scheduler_name: str = \"none\",\n",
    "                 step_size: int = 5,\n",
    "                 gamma: float = 0.5,\n",
    "                 ) -> None:\n",
    "        super().__init__()\n",
    "        ### Always need to call above function first in order\n",
    "        ### to properly initialize a model\n",
    "        '''Basic CNN to classify fashion MNIST\n",
    "        We aren't going to both with some of the fancier stuff from the MLP, but it's easy enough to apply here too\n",
    "        '''\n",
    "        \n",
    "        # model parameters\n",
    "        self.cnn_dim = cnn_layer_dim\n",
    "        self.mlp_dim = mlp_layer_dim\n",
    "        self.activation = activation\n",
    "        self.lr = lr\n",
    "        self.eps = eps\n",
    "        self.weight_decay = weight_decay\n",
    "        self.dropout = dropout\n",
    "        self.n_channels = n_channels\n",
    "        self.scheduler_name = scheduler_name\n",
    "        # if using a scheduler\n",
    "        self.step_size = step_size\n",
    "        self.gamma = gamma\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "        # log using WandB or TensorBoard\n",
    "        self.use_wandb = use_wandb\n",
    "        \n",
    "        # functions that keep track of accuracy during validation and testing\n",
    "        self.val_accuracy = torchmetrics.Accuracy(\"multiclass\", num_classes=n_classes)\n",
    "        self.test_accuracy = torchmetrics.Accuracy(\"multiclass\", num_classes=n_classes)\n",
    "\n",
    "        \n",
    "        # what the input data looks like (allows construction of graph for logging)\n",
    "        # (batch_size, channels, height, width)\n",
    "        self.example_input_array = torch.zeros(\n",
    "            (1, n_channels, input_xy, input_xy,),\n",
    "            dtype=torch.float32\n",
    "        )\n",
    "        \n",
    "        #### Construct the layers #####\n",
    "        ## get input layer\n",
    "        ## shape = (C, H, W) -> (cnn_layer_dim, H, W)\n",
    "        self.input_cnn = nn.Conv2d(n_channels, cnn_layer_dim, \n",
    "                                   kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "        \n",
    "        ## make CNN hidden layers\n",
    "        self.cnn_layers = []\n",
    "        for i in range(1, n_cnn_layers):\n",
    "            ##\n",
    "            self.cnn_layers.append(nn.Conv2d(cnn_layer_dim, cnn_layer_dim, \n",
    "                                       kernel_size=kernel_size, stride=stride, padding=padding))\n",
    "\n",
    "        self.cnn_layers = nn.ModuleList(self.cnn_layers)\n",
    "        \n",
    "        # get dimension of flat layer\n",
    "        flat_dim = self._flat_layer_size()\n",
    "        \n",
    "        # flatten output\n",
    "        self.flat = nn.Linear(int(flat_dim), mlp_layer_dim)\n",
    "        \n",
    "        # make MLP\n",
    "        self.mlp_layers = []\n",
    "        for i in range(1, n_mlp_layers):\n",
    "            self.mlp_layers.append(nn.Linear(mlp_layer_dim, mlp_layer_dim))\n",
    "        self.mlp_layers = nn.ModuleList(self.mlp_layers)\n",
    "        \n",
    "        # final output layer\n",
    "        self.output = nn.Linear(mlp_layer_dim, n_classes)\n",
    "\n",
    "        self.init_weights()\n",
    "        \n",
    "        # self.network = []\n",
    "        \n",
    "                \n",
    "    def _flat_layer_size(self) -> int:\n",
    "        \n",
    "        '''Gets the dimension of the flattened CNN output layer'''\n",
    "        \n",
    "        x = self.example_input_array\n",
    "        \n",
    "        # Pass the input tensor through the CNN layers\n",
    "        x = self.input_cnn(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        for layer in self.cnn_layers:\n",
    "            x = layer(x)\n",
    "            x = F.max_pool2d(x, 2)\n",
    "\n",
    "        # Calculate the flattened layer dimension\n",
    "        flattened_dim = x.view(1, -1).size(1)\n",
    "\n",
    "        return flattened_dim\n",
    "                \n",
    "\n",
    "    def forward(self, x):\n",
    "        '''Determines how data is passed through the network, \n",
    "           i.e creates the connectivity of the network'''\n",
    "        \n",
    "        ## send through input layer and activate\n",
    "        x = self.activation(self.input_cnn(x))\n",
    "        ## do max pooling (2x2)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "            \n",
    "        # pass through CNN\n",
    "        for layer in self.cnn_layers:\n",
    "            # pass through layer and activate\n",
    "            x = self.activation(layer(x))\n",
    "            # pool\n",
    "            x = F.max_pool2d(x, 2)\n",
    "        \n",
    "        # flatten output CNN layer to pass through MLP\n",
    "        x = x.view(x.size(0), -1)\n",
    "        # pass through MLP\n",
    "        x = self.flat(x)\n",
    "        for layer in self.mlp_layers:\n",
    "            x = self.activation(layer(x))\n",
    "            \n",
    "        # return output\n",
    "        x = self.output(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def configure_optimizers(self) -> (list, list):\n",
    "        \"\"\"Set up the optimizer and potential learning rate scheduler\"\"\"\n",
    "        self.optimizer = torch.optim.AdamW(\n",
    "            self.parameters(),\n",
    "            lr=self.lr,\n",
    "            eps=self.eps,\n",
    "            weight_decay=self.weight_decay,\n",
    "        )\n",
    "\n",
    "        if self.scheduler_name == \"none\":\n",
    "            return self.optimizer\n",
    "\n",
    "        ### this decreases the learning rate by a factor of gamma every step_size\n",
    "        self.scheduler = MultiStepLR(\n",
    "            self.optimizer,\n",
    "            list(range(0, self.trainer.max_epochs, self.step_size)),\n",
    "            gamma=self.gamma,\n",
    "        )\n",
    "\n",
    "        return [self.optimizer], [{\"scheduler\": self.scheduler, \"interval\": \"epoch\"}]\n",
    "        \n",
    "    #### need to add these two things in case the scheduler is used ####\n",
    "    def lr_scheduler_step(self, scheduler, metric) -> None:\n",
    "        if self.scheduler_name != \"none\":\n",
    "            self.scheduler.step()\n",
    "\n",
    "    def on_epoch_end(self) -> None:\n",
    "        if self.scheduler_name != \"none\":\n",
    "            self.scheduler.step()\n",
    "\n",
    "    def init_weights(self) -> None:\n",
    "        ### does some fancy layer weight initialization\n",
    "        for layer in self.mlp_layers:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                nn.init.xavier_uniform_(layer.weight)\n",
    "\n",
    "    def process_batch(self, batch, step: str = \"train\"):\n",
    "        \"\"\"Passes and logs a batch for a given type of step (test, train, validation)\"\"\"\n",
    "        \n",
    "        # get data\n",
    "        x, y = batch\n",
    "\n",
    "        # pass through network\n",
    "        # logits have no activation applied\n",
    "        logits = self(x)\n",
    "        \n",
    "        ## get loss\n",
    "        ## F.cross_entropy applies softmax then gets cross entropy,\n",
    "        ## so we don't need to activate the network output\n",
    "        loss = F.cross_entropy(logits, y) \n",
    "        \n",
    "        # record the loss\n",
    "        self.log(f\"{step}_loss\", loss)\n",
    "        if step in [\"val\", \"test\"]:\n",
    "            scores = self.softmax(logits)\n",
    "            # predicted class is the one with the maximum output probability\n",
    "            preds = torch.argmax(scores, dim=1)\n",
    "            # get accuracy\n",
    "            if step == \"val\":\n",
    "                self.val_accuracy.update(preds, y)\n",
    "                acc = float(self.val_accuracy(preds, y).detach().cpu().numpy().item())\n",
    "            else:\n",
    "                self.test_accuracy.update(preds, y)\n",
    "                acc = float(self.test_accuracy(preds, y).detach().cpu().numpy().item())\n",
    "            self.log(f\"{step}_acc\", acc)\n",
    "            \n",
    "        \n",
    "        # upload the loss to WandB\n",
    "        if self.use_wandb:\n",
    "            log_dict = {f\"{step}_loss\": loss,}\n",
    "            if step in [\"val\", \"test\"]:\n",
    "                log_dict[f\"{step}_accuracy\"] = acc\n",
    "            wandb.log(log_dict)\n",
    "                    \n",
    "        return loss\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \"\"\"What do do with a training batch\"\"\"\n",
    "        \n",
    "        return self.process_batch(batch, step=\"train\")\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        '''Validation step (at the end of each epoch)'''\n",
    "        \n",
    "        return self.process_batch(batch, step=\"val\")\n",
    "        \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        \n",
    "        '''Test step is essentially the same as a validation step in this instance'''\n",
    "        return self.process_batch(batch, step=\"test\")\n",
    "\n",
    "    def activation_maps(self, x, depth: int=0) -> np.ndarray:\n",
    "        \n",
    "        '''Gets output activation of an arbitary CNN layer'''\n",
    "        \n",
    "        i = 0\n",
    "        # input layer\n",
    "        x = self.activation(self.input_cnn(x))\n",
    "        \n",
    "        if depth == 0:\n",
    "            return x.detach().numpy()\n",
    "        \n",
    "        i += 1\n",
    "        x = F.max_pool2d(x, 2)\n",
    "            \n",
    "        # pass through CNN and return when you reach the appropriate depth\n",
    "        for layer in self.cnn_layers:\n",
    "            x = self.activation(layer(x))\n",
    "            if i == depth:\n",
    "                return x.detach().numpy()\n",
    "            i += 1\n",
    "            x = F.max_pool2d(x, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac61fc1e-667e-46ea-8741-d3c42b4d84fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model hyper parameters \n",
    "lr = 1e-3\n",
    "eps = 1e-8\n",
    "weight_decay = 1e-6\n",
    "n_cnn_layers = 3\n",
    "n_mlp_layers = 6\n",
    "dropout = 0.25\n",
    "cnn_layer_dim  = 64\n",
    "mlp_layer_dim = 128\n",
    "n_classes = 10\n",
    "activation = F.gelu\n",
    "n_channels = 1\n",
    "stride = 1\n",
    "kernel_size = 3\n",
    "padding = 1\n",
    "scheduler_name = \"step\"\n",
    "gamma = 0.5\n",
    "step_size = 5\n",
    "\n",
    "## WandB stuff\n",
    "# log with WandB or TensorBoard\n",
    "use_wandb = False\n",
    "# do hyperparameter sweep with WandB\n",
    "use_sweep = False\n",
    "# WandB project name\n",
    "project_name = 'SimpleMNIST_CNN'\n",
    "# WandB lab name\n",
    "entity = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26aef4e-cea2-4ca7-b4b1-78e8d3d44fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_hparams = {'lr': lr,\n",
    "                 'eps': eps,\n",
    "                 'weight_decay': weight_decay,\n",
    "                 'n_cnn_layers': n_cnn_layers,\n",
    "                 'n_mlp_layers': n_mlp_layers,\n",
    "                 'dropout': dropout,\n",
    "                 'cnn_layer_dim': cnn_layer_dim,\n",
    "                 'mlp_layer_dim': mlp_layer_dim,\n",
    "                 'padding': padding,\n",
    "                 'kernel_size': kernel_size,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1049f09b-9653-4a63-80d6-8f0efcc9906f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = SimpleCNN(\n",
    "                  n_cnn_layers=n_cnn_layers, \n",
    "                  n_mlp_layers=n_mlp_layers, \n",
    "                  cnn_layer_dim=cnn_layer_dim, \n",
    "                  mlp_layer_dim=mlp_layer_dim,\n",
    "                  n_classes=n_classes, \n",
    "                  input_xy=input_xy, \n",
    "                  activation=activation, \n",
    "                  n_channels=n_channels,\n",
    "                  use_wandb=use_wandb,\n",
    "                  dropout=dropout, \n",
    "                  padding=padding,\n",
    "                  eps=eps, lr=lr, \n",
    "                  weight_decay=weight_decay,\n",
    "                  scheduler_name=scheduler_name,\n",
    "                  gamma=gamma,\n",
    "                  step_size=step_size,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe3062c-199c-42e9-b05b-db72992da2e9",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cf83ed-8ed9-44bc-99a6-28dbde3e081c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not use_wandb:\n",
    "    %load_ext tensorboard\n",
    "    cnn_logger = TensorBoardLogger(\"cnn_logs\", name=\"simple_mnist_fashion_cnn\")\n",
    "    run_name = \"cnn\"\n",
    "else:\n",
    "    logger_kwargs = {\n",
    "        \"resume\": \"allow\",\n",
    "        \"config\": model_hparams,\n",
    "    }\n",
    "    cnn_logger = WandbLogger(project=project_name, entity=entity, **logger_kwargs)\n",
    "    cnn_run_name = cnn_logger.experiment.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c7b9b8-37a7-491b-9ad6-b86829f3b7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the trainer\n",
    "cnn_trainer = pl.Trainer(\n",
    "    devices=devices,\n",
    "    accelerator=accelerator,\n",
    "    max_epochs=num_epochs,\n",
    "    log_every_n_steps=1,\n",
    "    logger=cnn_logger,\n",
    "    # reload_dataloaders_every_epoch=True,\n",
    "    callbacks=[\n",
    "        # ModelCheckpoint(\n",
    "        #     save_weights_only=False,\n",
    "        #     mode=\"min\",\n",
    "        #     monitor=\"val_acc\",\n",
    "        #     save_top_k=1,\n",
    "        #     every_n_epochs=1,\n",
    "        #     save_on_train_epoch_end=False,\n",
    "        #     dirpath=f\"/CNN_Checkpoints/{run_name}/\",\n",
    "        #     filename=f\"cnn_checkpoint_{run_name}\",\n",
    "        # ),\n",
    "        LearningRateMonitor(\"epoch\"),\n",
    "        progress.TQDMProgressBar(refresh_rate=1),\n",
    "        EarlyStopping(\n",
    "            monitor=\"val_acc\",\n",
    "            min_delta=0,\n",
    "            patience=10,\n",
    "            verbose=False,\n",
    "            mode=\"min\",\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "cnn_trainer.logger._log_graph = True\n",
    "cnn_trainer.logger._default_hp_metric = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b385c5-97d7-4e9d-a62e-110ee5eb06b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_trainer.fit(cnn_model, train_dataloaders=train_loader, val_dataloaders=val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c10d40-e504-4fd0-a515-31c7f3ba2b5d",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4514bf8f-ce12-4a35-91ff-548196ecbce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get test metrics\n",
    "test_results = cnn_trainer.test(cnn_model, test_loader)\n",
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0057034b-67ee-40ba-b72f-d798b1e85357",
   "metadata": {},
   "outputs": [],
   "source": [
    "## open up TensorBoard\n",
    "if not use_wandb:\n",
    "    %tensorboard --logdir cnn_logs --port 6007"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d32375-f614-4bb2-b24d-50f83a02b195",
   "metadata": {},
   "source": [
    "## Inspect activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b869515d-99e6-418b-8d6f-94111bdf8c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Do inference on test set\n",
    "## need to turn into torch tensor first\n",
    "X_test_infer = torch.from_numpy(X_test).float()\n",
    "y_test_infer = torch.from_numpy(y_test).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0dc969-8efc-41ed-b7de-8c0f6f3ed2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get intermediate activations\n",
    "activation_layer = 0\n",
    "\n",
    "## get a single activation layer\n",
    "if activation_layer >= 0:\n",
    "    activations = [cnn_model.activation_maps(X_test_infer[i:i+1], depth=0)[0, activation_layer, :, :] for i in range(2)]\n",
    "## option to get mean activation over all layers\n",
    "else:\n",
    "    activations = [np.mean(cnn_model.activation_maps(X_test_infer[i:i+1], depth=0)[0, :, :, :], axis=0) for i in range(2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecf8b42-7801-4c7f-8928-6afe22ffc849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot activations vs input\n",
    "images = list(X_test[:2, 0, :, :])\n",
    "images.extend(activations)\n",
    "plot_image_panel(images, labels=[classes[y_test[0]], classes[y_test[1]], '', ''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8360a807-6742-46a5-acca-d09c55fe0988",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
