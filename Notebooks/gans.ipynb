{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbcf8096-377a-481e-9876-2f6569773814",
   "metadata": {},
   "source": [
    "# Adversarial Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddde3e0-43c7-4e13-9f6e-029b612c6c22",
   "metadata": {},
   "source": [
    "Adversarial learning has become one of the most powerful and important tools in machine learning. It is the foundation for many types of generative models (e.g., GANs) as well as more advanced methods, such as domain adaptation. We'll stick to GANs, but the general framework is pretty similar.\n",
    "\n",
    "The basic idea is very simple: train one model to lie and train another model to figure out if the other model is lying. These models are \"adversaries\" in the sense that they are trying to beat the other (by tricking or calling out). As they train, the classifier learns what real data looks like and the generator learns how to create realistic looking data.\n",
    "\n",
    "1) Give the classifier some real data, reward it for saying it's real\n",
    "2) Give the classifier some data that comes from the generator, reward it for saying it's faked\n",
    "3) Feed random noise into generator, send the output into the classifier, reward generator if the classifier says it's real\n",
    "\n",
    "Through this loop, the classifier learns how to detect lies better and the generator figures out how to lie more convincingly. This encourages the generator to make data that is as close to the real data as possible, even though the input is simply noise. In other words, it learns how to take noise and turn it into convincing data.\n",
    "\n",
    "<div>\n",
    "<img src=\"imgs/gan.jpg\" width=\"1000\" style=\"display=block; margin:auto\" align=\"center\"/>\n",
    "</div>\n",
    "\n",
    "https://www.xenonstack.com/insights/generative-adversarial-networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5eb26e-3f8a-4226-b6d3-54c784c69102",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"imgs/stylegan.jpeg\" width=\"600\" style=\"display=block; margin:auto\" align=\"center\"/>\n",
    "</div>\n",
    "GAN image (Wikipedia)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbf8e33-ea49-49b4-942c-28695449cc40",
   "metadata": {},
   "source": [
    "Nowadays, diffusion models (e.g., DALL-E) have become increasingly used in image generation, but GANs and adverasial learning in general still have an important place."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5857392-d983-496d-95ed-130e0c611c7a",
   "metadata": {},
   "source": [
    "### Domain adaptation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69531c37-323c-4e76-a898-cdb55869467f",
   "metadata": {},
   "source": [
    "Domain adaptation is another interesting area for adversarial learning. In combines both adversarial learning and encoding/decoding to allow models to perform across different domains (e.g., different telescopes, observations+simulations,...)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e233f3d-bae7-41a4-a6c2-dc7dae064005",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"imgs/domain_adaptation_results.jpg\" width=\"1200\" style=\"display=block; margin:auto\" align=\"center\"/>\n",
    "</div>\n",
    "(Alexander et al. 2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83694e9c-8dea-477c-b1ef-b4666adfec28",
   "metadata": {},
   "source": [
    "The idea is to create an encoder-decoder model for a clean (\"source\") dataset, e.g., raw simulations. After this is trained, a dirty (\"target\") dataset, e.g., simulations with observational effects, is used to train another encoder. This encoder is trained adversarially to map the target dataset into the same latent space as the source dataset. In other words, an encoder is trained such that a classifier can't tell the difference between the encoded source and target data. When this is now passed through the decoder, the hard problem (target data) is now as easy as the easier problem (source data). This has been shown to have significant improvements over simply training on the target data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab99854-cb77-499b-b490-c34acb734dab",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92c7174e-9526-49ee-ac22-aabe1fce923f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting a prameters\n",
    "scale_factor = 1.5\n",
    "\n",
    "labels = 16 * scale_factor\n",
    "ticks = 10 * scale_factor\n",
    "# ticks = 10 * scale_factor\n",
    "legends = 12 * scale_factor\n",
    "text = 14 * scale_factor\n",
    "titles = 22 * scale_factor\n",
    "lw = 3 * scale_factor\n",
    "ps = 200 * scale_factor\n",
    "cmap = 'magma'\n",
    "\n",
    "colors = ['firebrick', 'steelblue', 'darkorange', 'darkviolet', 'cyan', 'magenta', 'darkgreen', 'deeppink']\n",
    "markers = ['x', 'o', '+', '>', '*', 'D', '4']\n",
    "linestyles = ['-', '--', ':', '-.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff14fed2-13ce-4cc9-b896-ad55ce737793",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import PIL\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint, progress\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.loggers import WandbLogger, TensorBoardLogger\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torch.utils.data import DataLoader, Dataset, RandomSampler, random_split\n",
    "\n",
    "import torchmetrics\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2846ea57-5c58-450e-83b8-03be2cc61dd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x16743e590>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Set seed for reproducibility\n",
    "np.random.seed(123)\n",
    "random.seed(123)\n",
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39a9765-378a-43e7-900e-17ca30fc2d66",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab0bacc2-e140-405e-8d0e-755abbd4507d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define loading transformations\n",
    "transforms = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    # T.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "### Download fashion MNIST\n",
    "train_dataset = datasets.FashionMNIST(\n",
    "    root='./data', train=True, download=True,\n",
    "    transform=transforms)\n",
    "test_dataset = datasets.FashionMNIST(\n",
    "    root='./data', train=False, download=True,\n",
    "    transform=transforms)\n",
    "\n",
    "### make data loaders\n",
    "batch_size = 32\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbcbf8b7-ea95-45d3-a4a0-8754f1d4ff92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasonterry/miniforge3/envs/pytorch_python10/lib/python3.10/site-packages/torchvision/datasets/mnist.py:75: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n"
     ]
    }
   ],
   "source": [
    "xy = int(train_dataset.train_data.size(1) * train_dataset.train_data.size(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553b584a-1dcb-4138-bc44-d831dbabc925",
   "metadata": {},
   "source": [
    "## Define models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3175b3-3a47-4c16-a9e6-7cfe1fbc44f8",
   "metadata": {},
   "source": [
    "### Individual models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c498f004-30bf-4d9b-a1eb-677bdd1a9eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int = 784,\n",
    "        output_dim: int = 1,\n",
    "        lr: float = 1e-4,\n",
    "        weight_decay: float = 1e-8,\n",
    "        adam_eps: float = 1e-7,\n",
    "        weight_init: str = \"xavier\",\n",
    "        num_mlp_layers: int = 5,\n",
    "        mlp_layer_dim: int = 128,\n",
    "        activation: str = \"gelu\",\n",
    "        leaky_relu_frac: float = 0.2,\n",
    "        dropout: float = 0.2,\n",
    "        loss = nn.BCELoss(),\n",
    "        feature_factor: float = 2.,\n",
    "        final_activation = nn.Sigmoid(),\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        self.lr = lr\n",
    "        self.weight_decay = weight_decay\n",
    "        self.adam_eps = adam_eps\n",
    "        self.weight_init = weight_init\n",
    "        self.num_mlp_layers = num_mlp_layers\n",
    "        self.mlp_layer_dim = mlp_layer_dim\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.output_layers = nn.ModuleList()\n",
    "        self.activation_layers = nn.ModuleList()\n",
    "\n",
    "        for _i in range(num_mlp_layers):\n",
    "            if _i > 0:\n",
    "                # import pdb; pdb.set_trace()\n",
    "                self.layers.append(nn.Linear(self.layers[-1].out_features, \n",
    "                                             int(feature_factor*self.layers[-1].out_features)))\n",
    "            else:\n",
    "                self.layers.append(nn.Linear(self.input_dim, mlp_layer_dim))\n",
    "\n",
    "            self.activation_layers.append(\n",
    "                nn.GELU() if activation == \"gelu\" else nn.LeakyReLU(leaky_relu_frac, inplace=True)\n",
    "            )\n",
    "            self.activation_layers.append(nn.Dropout(dropout))\n",
    "\n",
    "        self.output_layers.append(nn.Linear(self.layers[-1].out_features, self.output_dim))\n",
    "        self.output_layers.append(final_activation)\n",
    "\n",
    "        self.init_weights()  # Initialize the weights\n",
    "\n",
    "        self.loss = loss\n",
    "\n",
    "    def init_weights(self):\n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                if self.weight_init == \"xavier\":\n",
    "                    nn.init.xavier_uniform_(layer.weight)  # Apply Xavier initialization\n",
    "                elif self.weight_init == \"kaiming\":\n",
    "                    nn.init.kaiming_uniform_(layer.weight)  # Apply Kaiming initialization\n",
    "                elif self.weight_init == \"orthogonal\":\n",
    "                    nn.init.orthogonal_(layer.weight)  # Apply orthogonal initialization\n",
    "\n",
    "                nn.init.constant_(layer.bias, 0.0)\n",
    "\n",
    "    def forward(self, z):\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            z = layer(z)\n",
    "            z = self.activation_layers[i](z)\n",
    "        for layer in self.output_layers:\n",
    "            z = layer(z)\n",
    "        return z\n",
    "\n",
    "    # def configure_optimizers(self):\n",
    "    #     self.optimizer = torch.optim.Adam(\n",
    "    #         self.parameters(), lr=self.lr, eps=self.adam_eps, weight_decay=self.weight_decay\n",
    "    #     )\n",
    "    #     return self.optimizer\n",
    "\n",
    "\n",
    "class Generator(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int = 64,\n",
    "        output_dim: int = 784,\n",
    "        lr: float = 1e-4,\n",
    "        weight_decay: float = 1e-8,\n",
    "        adam_eps: float = 1e-7,\n",
    "        weight_init: str = \"xavier\",\n",
    "        num_mlp_layers: int = 3,\n",
    "        mlp_layer_dim: int = 128,\n",
    "        activation: str = \"gelu\",\n",
    "        leaky_relu_frac: float = 0.2,\n",
    "        dropout: float = 0.2,\n",
    "        loss = nn.BCELoss(),\n",
    "        feature_factor: float = 2.,\n",
    "        final_activation = nn.Tanh(),\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.model = MLP(input_dim=input_dim,\n",
    "                         output_dim=output_dim,\n",
    "                         lr=lr,\n",
    "                         weight_decay=weight_decay,\n",
    "                         adam_eps=adam_eps,\n",
    "                         weight_init=weight_init,\n",
    "                         num_mlp_layers=num_mlp_layers,\n",
    "                         mlp_layer_dim=mlp_layer_dim,\n",
    "                         activation=activation,\n",
    "                         leaky_relu_frac=leaky_relu_frac,\n",
    "                         dropout=dropout,\n",
    "                         loss=loss,\n",
    "                         feature_factor=feature_factor,\n",
    "                         final_activation=final_activation,\n",
    "                        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.model(z)\n",
    "\n",
    "    # def configure_optimizers(self):\n",
    "    #     self.optimizer = torch.optim.Adam(\n",
    "    #         self.parameters(), lr=self.lr, eps=self.adam_eps, weight_decay=self.weight_decay\n",
    "    #     )\n",
    "    #     return self.optimizer\n",
    "        \n",
    "\n",
    "class Discriminator(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int = 784,\n",
    "        output_dim: int = 1,\n",
    "        lr: float = 1e-4,\n",
    "        weight_decay: float = 1e-8,\n",
    "        adam_eps: float = 1e-7,\n",
    "        weight_init: str = \"xavier\",\n",
    "        num_mlp_layers: int = 3,\n",
    "        mlp_layer_dim: int = 128,\n",
    "        activation: str = \"gelu\",\n",
    "        leaky_relu_frac: float = 0.2,\n",
    "        dropout: float = 0.2,\n",
    "        loss = nn.BCELoss(),\n",
    "        feature_factor: float = 2.,\n",
    "        final_activation = nn.Sigmoid(),\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.model = MLP(input_dim=input_dim,\n",
    "                         output_dim=output_dim,\n",
    "                         lr=lr,\n",
    "                         weight_decay=weight_decay,\n",
    "                         adam_eps=adam_eps,\n",
    "                         weight_init=weight_init,\n",
    "                         num_mlp_layers=num_mlp_layers,\n",
    "                         mlp_layer_dim=mlp_layer_dim,\n",
    "                         activation=activation,\n",
    "                         leaky_relu_frac=leaky_relu_frac,\n",
    "                         dropout=dropout,\n",
    "                         loss=loss,\n",
    "                         feature_factor=feature_factor,\n",
    "                         final_activation=final_activation,\n",
    "                        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.model(z)\n",
    "\n",
    "    # def configure_optimizers(self):\n",
    "    #     self.optimizer = torch.optim.Adam(\n",
    "    #         self.parameters(), lr=self.lr, eps=self.adam_eps, weight_decay=self.weight_decay\n",
    "    #     )\n",
    "    #     return self.optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d253758f-8281-4878-8dab-c1ca40448bb4",
   "metadata": {},
   "source": [
    "### Combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54c14c8c-8d22-4f4c-a033-a9b57b80aca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        img_dim: int = 784,\n",
    "        latent_dim: int = 64,\n",
    "        lr: float = 1e-4,\n",
    "        weight_decay: float = 1e-8,\n",
    "        adam_eps: float = 1e-7,\n",
    "        weight_init: str = \"xavier\",\n",
    "        use_batchnorm: bool = False,\n",
    "        num_mlp_layers: int = 3,\n",
    "        mlp_layer_dim: int = 128,\n",
    "        activation: str = \"gelu\",\n",
    "        dropout: float = 0.2,\n",
    "        padded_spectra: bool = False,\n",
    "        encoder_name: str = \"\",\n",
    "        # **kwargs: dict,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        # do this because we are using multiple optimizers\n",
    "        self.automatic_optimization = False\n",
    "\n",
    "        self.img_dim = img_dim\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        self.classifier = Discriminator(\n",
    "            input_dim=img_dim,\n",
    "            feature_factor=0.5,\n",
    "        )\n",
    "\n",
    "        self.generator = Generator(\n",
    "            input_dim=latent_dim,\n",
    "            output_dim=img_dim,\n",
    "            feature_factor=2.,\n",
    "        )\n",
    "\n",
    "        self.lr = lr\n",
    "        self.weight_decay = weight_decay\n",
    "        self.adam_eps = adam_eps\n",
    "        self.weight_init = weight_init\n",
    "        self.activation = activation\n",
    "\n",
    "\n",
    "    def process_batch(self, x, step: str = \"train\"):\n",
    "        \n",
    "        # get optimizers (different for each model)\n",
    "        d_opt, g_opt = self.optimizers()\n",
    "\n",
    "        batch_size = x.shape[0]\n",
    "\n",
    "        ##### train discrimator ####\n",
    "        # these are real (hence, 1)\n",
    "        x_real = x.view(-1, self.img_dim).float().to(self.device)\n",
    "        y_real = torch.ones(batch_size, 1).float().to(self.device)\n",
    "\n",
    "        # classify real data\n",
    "        real_classification = self.classifier(x_real)\n",
    "\n",
    "        # get classifier loss\n",
    "        real_loss = self.classifier.model.loss(real_classification, y_real)\n",
    "\n",
    "        # now use fake data (y = 0)/random input\n",
    "        z = torch.randn(batch_size, self.latent_dim).float().to(device)\n",
    "        \n",
    "        # send random data through generator\n",
    "        x_fake = self.generator(z)\n",
    "        y_fake = torch.zeros(batch_size, 1).float().to(device)\n",
    "    \n",
    "        fake_classification = self.classifier(x_fake)\n",
    "        fake_loss = self.classifier.model.loss(fake_classification, y_fake)\n",
    "\n",
    "        class_loss = 0.5 * (fake_loss + real_loss)\n",
    "\n",
    "        if step == \"train\":\n",
    "            d_opt.zero_grad()\n",
    "            self.manual_backward(class_loss)\n",
    "            d_opt.step()\n",
    "\n",
    "            \n",
    "        ##### train generator ####\n",
    "        # random input\n",
    "        z = torch.randn(batch_size, self.latent_dim).float().to(device)\n",
    "\n",
    "        # 1 because we are trying to trick classifier\n",
    "        gen_labels = torch.ones(batch_size, 1).to(device)\n",
    "\n",
    "        # generate some data\n",
    "        gen_output = self.generator(z)\n",
    "        # classify data\n",
    "        class_output = self.classifier(gen_output)\n",
    "        gen_loss = self.classifier.model.loss(class_output, gen_labels)\n",
    "\n",
    "        if step == \"train\":\n",
    "            g_opt.zero_grad()\n",
    "            self.manual_backward(gen_loss)\n",
    "            g_opt.step()\n",
    "\n",
    "        self.log(f\"{step}_d_loss\", class_loss)\n",
    "\n",
    "        self.log(f\"{step}_g_loss\", gen_loss)\n",
    "\n",
    "        return {f\"{step}_d_loss\": class_loss, f\"{step}_g_loss\": gen_loss}\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # import pdb; pdb.set_trace()\n",
    "        x, _ = batch\n",
    "        return self.process_batch(x, step=\"train\")\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, _ = batch\n",
    "        return self.process_batch(x, step=\"val\")\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, _ = batch\n",
    "        return self.process_batch(x, step=\"test\")\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        ## one optimizer for each model\n",
    "        self.d_opt = torch.optim.Adam(\n",
    "            self.classifier.model.parameters(), lr=self.lr, eps=self.adam_eps, weight_decay=self.weight_decay\n",
    "        )\n",
    "        self.g_opt = torch.optim.Adam(\n",
    "            self.generator.model.parameters(), lr=self.lr, eps=self.adam_eps, weight_decay=self.weight_decay\n",
    "        )\n",
    "        return self.d_opt, self.g_opt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a270db-9555-4a50-8359-acc2bae51143",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad49eb37-8b40-4698-8d22-6380871fad7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "accelerator_name = \"mps\"\n",
    "accelerator_name = \"cpu\"\n",
    "\n",
    "# boilerplate to get GPU if possible\n",
    "if accelerator_name == \"mps\":\n",
    "    device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "elif accelerator_name == \"cuda\":\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "# Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "torch.backends.cudnn.determinstic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f41ff0c-7bce-445b-b1e4-c1bcdb623b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_wandb = False\n",
    "if not use_wandb:\n",
    "    %load_ext tensorboard\n",
    "    cnn_logger = TensorBoardLogger(\"gan_logs\", name=\"mnist_fashion_gan\")\n",
    "    run_name = \"cnn\"\n",
    "else:\n",
    "    logger_kwargs = {\n",
    "        \"resume\": \"allow\",\n",
    "        \"config\": model_hparams,\n",
    "    }\n",
    "    cnn_logger = WandbLogger(project=project_name, entity=entity, **logger_kwargs)\n",
    "    cnn_run_name = cnn_logger.experiment.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3e76dad-6314-4bb8-bbf3-dd0c2df9e9bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/jasonterry/miniforge3/envs/pytorch_python10/lib/python3.10/site-packages/pytorch_lightning/trainer/setup.py:201: UserWarning: MPS available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='mps', devices=1)`.\n",
      "  rank_zero_warn(\n"
     ]
    }
   ],
   "source": [
    "#### necessary for newer PTL versions\n",
    "devices = 1 \n",
    "accelerator = \"gpu\" if accelerator_name != \"cpu\" else \"cpu\"\n",
    "\n",
    "# make the trainer\n",
    "trainer = pl.Trainer(\n",
    "    devices=devices,\n",
    "    accelerator=accelerator,\n",
    "    max_epochs=num_epochs,\n",
    "    log_every_n_steps=1,\n",
    "    logger=cnn_logger,\n",
    "    # reload_dataloaders_every_epoch=True,\n",
    "    callbacks=[\n",
    "        LearningRateMonitor(\"epoch\"),\n",
    "        progress.TQDMProgressBar(refresh_rate=1),\n",
    "        EarlyStopping(\n",
    "            monitor=\"train_d_loss\",\n",
    "            min_delta=0,\n",
    "            patience=15,\n",
    "            verbose=False,\n",
    "            mode=\"min\",\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "trainer.logger._log_graph = True\n",
    "trainer.logger._default_hp_metric = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40c02fca-ae0a-4e5d-a789-abe89c81f072",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 100\n",
    "num_mlp_layers = 5\n",
    "mlp_layer_dim = 128\n",
    "gan = GAN(img_dim=xy, latent_dim=latent_dim, mlp_layer_dim=mlp_layer_dim, num_mlp_layers=num_mlp_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8957e2f7-6b0b-4da5-97f4-1923ce017259",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasonterry/miniforge3/envs/pytorch_python10/lib/python3.10/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: PossibleUserWarning: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "  rank_zero_warn(\n",
      "\n",
      "  | Name       | Type          | Params\n",
      "---------------------------------------------\n",
      "0 | classifier | Discriminator | 110 K \n",
      "1 | generator  | Generator     | 579 K \n",
      "---------------------------------------------\n",
      "690 K     Trainable params\n",
      "0         Non-trainable params\n",
      "690 K     Total params\n",
      "2.762     Total estimated model params size (MB)\n",
      "/Users/jasonterry/miniforge3/envs/pytorch_python10/lib/python3.10/site-packages/pytorch_lightning/loggers/tensorboard.py:190: UserWarning: Could not log computational graph to TensorBoard: The `model.example_input_array` attribute is not set or `input_array` was not given.\n",
      "  rank_zero_warn(\n",
      "/Users/jasonterry/miniforge3/envs/pytorch_python10/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:432: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 10 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f8535dd16f742a7b5f75fab2fd2fc60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(gan, train_dataloaders=train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed093855-08dc-4455-b15b-072ac1b97a1c",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36f5df4f-b22c-44db-9e3a-2789fcf37a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasonterry/miniforge3/envs/pytorch_python10/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:432: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 10 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ecde7082bd9479190819fbb4f0ad2f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       test_d_loss          0.6775009036064148\n",
      "       test_g_loss          0.6776726841926575\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "[{'test_d_loss': 0.6775009036064148, 'test_g_loss': 0.6776726841926575}]\n"
     ]
    }
   ],
   "source": [
    "## Get test metrics\n",
    "test_results = trainer.test(gan, test_loader)\n",
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cb6b8564-7a26-4064-b204-6fc1a62e0725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-443cdef36840ff07\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-443cdef36840ff07\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6003;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## open up TensorBoard\n",
    "if not use_wandb:\n",
    "    %tensorboard --logdir gan_logs --port 6003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47af1cf5-e22e-4ff8-9798-73680a1da7e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6db15892-0520-4056-861e-25c17d0fde5d",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98f5d100-3146-4a45-a9ee-9f0aa5c173eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_imgs = 10\n",
    "random_inputs = torch.randn(num_imgs, latent_dim).float().to(device)\n",
    "\n",
    "generated_imgs = gan.generator(random_inputs).view(num_imgs, 1, 28, 28).detach().cpu().numpy().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "db984f8c-6459-480b-82a0-ff55d9952717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10., 10.))\n",
    "\n",
    "img_index = 0\n",
    "plt.imshow(generated_imgs[img_index], cmap=\"viridis\")\n",
    "\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"\")\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7950e4c7-f6e6-42e6-885b-d26ba2390b31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10., 10.))\n",
    "\n",
    "img_index = 0\n",
    "plt.imshow(train_dataset[img_index][0].numpy().squeeze(), cmap=\"viridis\")\n",
    "\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"\")\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875dd689-4a41-491d-ae7e-04b5821f7462",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
